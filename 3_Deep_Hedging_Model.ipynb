{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d5a508-c46d-4e57-899a-bbdf36efc517",
   "metadata": {},
   "source": [
    "# 3. Deep Hedging Model\n",
    "\n",
    "In this notebook, we implement and train a neural network that learns to hedge a European call option dynamically using simulated market data.\n",
    "\n",
    "> **Goal.** Train a trading policy $(a_t)$ that minimizes **tail risk** (CVaR) of the terminal hedging error\n",
    "> $$\n",
    "X \\;=\\; -Z_T \\;+\\; \\sum_{t=0}^{T-1} a_t\\,\\Delta S_t \\;-\\; \\underbrace{\\gamma\\sum_{t=0}^{T-1} S_t\\,|a_t - a_{t-1}|}_{\\text{transaction cost}}\n",
    " $$\n",
    "> on simulated paths from Notebook 2. We do this end-to-end with a recurrent policy network, a symbolic rollout, and a Rockafellar–Uryasev (RU) CVaR head.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1) What this notebook consumes / produces\n",
    "\n",
    "**Inputs (from Notebook 2):**\n",
    "- `data/S_train.npy`, `S_val.npy`, `S_test.npy`  — each shape `(N, n_steps+1)`\n",
    "- `data/Z_T_train.npy`, `Z_T_val.npy`, `Z_T_test.npy`  — each shape `(N,)`\n",
    "- `data/meta.json` — `S0`, `K`, `T`, `n_steps`, `dt`, plus knobs like `alpha`, `gamma`, `h_max` (optional)\n",
    "\n",
    "**Outputs (used by Notebook 4):**\n",
    "- Trained weights (best by tail metrics)\n",
    "- Arrays for backtesting: $(X)$, $(\\text{PnL})$, $(\\text{cost})$, $(\\text{turnover})$, $(Z_T)$, and optionally positions $(a_t)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2) Setup & reproducibility\n",
    "\n",
    "**What to do here:**\n",
    "- Import `numpy`, `tensorflow` (Keras), `json`, `pathlib`.\n",
    "- Fix seeds (`tf.keras.utils.set_random_seed(SEED)`).\n",
    "- Read `meta.json`, unpack: `S0, K, T_years, n_steps, dt`.  \n",
    "- Choose training knobs (typical defaults shown; adjust later in §12):\n",
    "  - `ALPHA = 0.90` (CVaR level)\n",
    "  - `GAMMA = 0.001` (turnover cost scale; ≈10 bps)\n",
    "  - `H_MAX = 5` (position clamp \\(|a_t|\\le H_{\\max}\\))\n",
    "  - `BATCH`, `EPOCHS`, `LR`\n",
    "- Load arrays `S_*` and `Z_T_*` and print shapes (sanity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee57b39-bcce-48c0-b7fd-97b6bff44c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: S_train (8000, 253), S_val (5000, 253), S_test (5000, 253)\n",
      "Payoffs: Z_T_train (8000,), Z_T_val (5000,), Z_T_test (5000,)\n",
      "n_steps = 252, N_train = (8000,), N_val = (5000,), N_test = (5000,)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook 3 (Keras) — Deep Hedging with CVaR Utility\n",
    "# ============================================================\n",
    "# Requirements: TensorFlow 2.x (tf.keras), numpy, Keras 3\n",
    "# Inputs:   data/S_train.npy, S_val.npy, S_test.npy\n",
    "#           data/Z_T_train.npy, Z_T_val.npy, Z_T_test.npy\n",
    "#           data/meta.json  (S0, K, T, n_steps, dt, alpha, etc.)\n",
    "# Output:   results/hedging_eval_test_keras.npz  (keys: V_T, Z_T)\n",
    "# ============================================================\n",
    "\n",
    "import os, json, math, time\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # quiet TF logs\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# --------------------------\n",
    "# 0) Repro + folders\n",
    "# --------------------------\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "# tf.config.experimental.enable_op_determinism()  # keep off for speed unless you need bit-exact\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "RESULTS_DIR = Path(\"results\"); RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --------------------------\n",
    "# 1) Load meta + raw arrays\n",
    "# --------------------------\n",
    "with open(DATA_DIR/\"meta.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "S0       = float(meta[\"S0\"])\n",
    "K        = float(meta[\"K\"])\n",
    "T_years  = float(meta[\"T\"])\n",
    "n_steps  = int(meta[\"n_steps\"])\n",
    "dt       = float(meta[\"dt\"])\n",
    "n_feat   = 4 \n",
    "\n",
    "# --------------------------\n",
    "# 2) Training knobs\n",
    "# --------------------------\n",
    "ALPHA  = 0.9 # CVaR tail level\n",
    "GAMMA  = 0.0005 # Transaction cost scale γ = 0.001 (10 bps per unit turnover)\n",
    "H_MAX  = 5 # max abs(position)\n",
    "BATCH  = 400 # for ALPHA=0.95 ~ 400\n",
    "EPOCHS = 150\n",
    "LR     = 1e-3\n",
    "\n",
    "S_train = np.load(DATA_DIR/\"S_train.npy\")   # (N_train, n_steps+1)\n",
    "S_val   = np.load(DATA_DIR/\"S_val.npy\")\n",
    "S_test  = np.load(DATA_DIR/\"S_test.npy\")\n",
    "\n",
    "Z_T_train = np.load(DATA_DIR/\"Z_T_train.npy\").astype(np.float32)\n",
    "Z_T_val   = np.load(DATA_DIR/\"Z_T_val.npy\").astype(np.float32)\n",
    "Z_T_test  = np.load(DATA_DIR/\"Z_T_test.npy\").astype(np.float32)\n",
    "\n",
    "print(f\"Loaded: S_train {S_train.shape}, S_val {S_val.shape}, S_test {S_test.shape}\")\n",
    "print(f\"Payoffs: Z_T_train {Z_T_train.shape}, Z_T_val {Z_T_val.shape}, Z_T_test {Z_T_test.shape}\")\n",
    "print(f\"n_steps = {n_steps}, N_train = {S_train[:,0].shape}, N_val = {S_val[:,0].shape}, N_test = {S_test[:,0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7d406-2cec-4d46-ab56-c85db1cead5a",
   "metadata": {},
   "source": [
    "## 3.3) Build *causal* features and $(\\Delta S)$\n",
    "\n",
    "**What to do here:**\n",
    "- From each `S` (shape `(N, n_steps+1)`) compute:\n",
    "  - $(S_t := S[:, 0:n\\_steps])$\n",
    "  - $(S_{t+1} := S[:, 1:n\\_steps+1])$\n",
    "  - $(\\Delta S_t = S_{t+1} - S_t)$ → shape `(N, n_steps, 1)`\n",
    "- Causal features per time step $(t)$ (shape `(N, n_steps, 4)`):\n",
    "  1. `price_norm`: $(S_t / S_0)$\n",
    "  2. `tau`: linear grid $(\\tau_t = (T - t)/T)$\n",
    "  3. `logR_past`: **lagged** log return; at $(t=0)$ set to `0`, for $(t>0)$ use $(\\log S_t - \\log S_{t-1})$\n",
    "  4. `vol_ann`: rolling std of `logR_past` over a window (e.g., 20), annualized by $(\\sqrt{1/dt})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8482d5e0-69fd-4644-a711-785850a81735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature tensor shapes: \n",
      " dSt_train: (8000, 252, 1) \n",
      "  X_train: (8000, 252, 4) \n",
      "  X_val:   (5000, 252, 4) \n",
      "  X_test:  (5000, 252, 4) \n",
      "  Z_train: (8000,) \n",
      "  Z_val:   (5000,) \n",
      "  Z_test:  (5000,)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3) Causal features: [price_norm, tau, log_return, realized_vol_annualized]\n",
    "# --------------------------\n",
    "def build_features_from_S(S, S0, n_steps, dt, win=20):\n",
    "    N = S.shape[0]\n",
    "    St      = S[:,:-1]                # (N, n_steps)\n",
    "    St_p1 = S[:, 1:]\n",
    "    \n",
    "    dSt = (St_p1 - St)[:,:,np.newaxis].astype(np.float32)\n",
    "    price_norm = St / S0\n",
    "\n",
    "    r_next = np.diff(np.log(S), axis=1).astype(np.float32)\n",
    "    logR_past = np.zeros_like(r_next, dtype=np.float32)     # (N, n_steps)\n",
    "    if n_steps > 1:\n",
    "        logR_past[:, 1:] = r_next[:, :-1]\n",
    "\n",
    "    tau_vec = np.linspace(1.0 - 1.0/n_steps, 0.0, n_steps, dtype=np.float32)\n",
    "    tau     = np.broadcast_to(tau_vec, (N, n_steps))\n",
    "\n",
    "    vol = np.empty_like(logR_past, dtype=np.float32)\n",
    "    for t in range(n_steps):\n",
    "        l = max(0, t - win + 1)\n",
    "        w = logR_past[:, l:t+1]\n",
    "        vol[:, t] = w.std(axis=1)\n",
    "    steps_per_year = int(round(1.0 / dt))\n",
    "    vol_ann = vol * np.sqrt(steps_per_year)\n",
    "\n",
    "    X = np.stack([price_norm, tau, logR_past, vol_ann], axis=-1).astype(np.float32)\n",
    "    return dSt, X, logR_past.astype(np.float32), vol_ann.astype(np.float32)\n",
    "\n",
    "dSt_train, X_train, logR_train, vol_train = build_features_from_S(S_train, S0, n_steps, dt, win=20)\n",
    "dSt_val, X_val,   logR_val,   vol_val   = build_features_from_S(S_val,   S0, n_steps, dt, win=20)\n",
    "dSt_test, X_test,  logR_test,  vol_test  = build_features_from_S(S_test,  S0, n_steps, dt, win=20)\n",
    "\n",
    "Z_T_train = np.asarray(Z_T_train, dtype=np.float32).reshape(-1)\n",
    "Z_T_val   = np.asarray(Z_T_val,   dtype=np.float32).reshape(-1)\n",
    "Z_T_test  = np.asarray(Z_T_test,  dtype=np.float32).reshape(-1)\n",
    "\n",
    "print(\"Feature tensor shapes:\",\n",
    "      \"\\n dSt_train:\", dSt_train.shape,\n",
    "      \"\\n  X_train:\", X_train.shape,\n",
    "      \"\\n  X_val:  \", X_val.shape,\n",
    "      \"\\n  X_test: \", X_test.shape,\n",
    "      \"\\n  Z_train:\", Z_T_train.shape,\n",
    "      \"\\n  Z_val:  \", Z_T_val.shape,\n",
    "      \"\\n  Z_test: \", Z_T_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86acdbe-d50c-4311-87ea-f734ef43df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train  = X_train.shape[0]\n",
    "n_val  = X_val.shape[0]\n",
    "n_test  = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1ee6a-753d-442f-b590-547f44c0c59d",
   "metadata": {},
   "source": [
    "## 3.4) Build `tf.data` pipelines\n",
    "\n",
    "**What to do here:**\n",
    "- Construct dictionaries per split:\n",
    "  - `inputs = {\"features\": X, \"dS\": dS, \"Z_T\": Z_T}`  \n",
    "    (keep `Z_T` **1D** `(N,)`; you can expand later if needed)\n",
    "  - `labels = zeros(N)`  (dummy; our loss reads from the graph)\n",
    "- Create datasets:\n",
    "  - `train_ds = Dataset.from_tensor_slices((inputs, labels)).cache().shuffle(...).batch(BATCH).prefetch(AUTOTUNE)`\n",
    "  - Similarly for `val_ds` (no shuffle) and `test_ds`.\n",
    "- **Peek a batch** and print dtypes/shapes to confirm:\n",
    "  - `features: (BATCH, n_steps, 4)`\n",
    "  - `dS:       (BATCH, n_steps, 1)`\n",
    "  - `Z_T:      (BATCH,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902a04d1-a0f0-49e7-8753-ad87d8e4e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 4) Datasets\n",
    "# --------------------------\n",
    "\n",
    "inputs = {\n",
    "    \"features\": X_train[:,:,:],\n",
    "    \"dS\": dSt_train[:,:,:],\n",
    "    \"Z_T\": Z_T_train[:]\n",
    "}\n",
    "\n",
    "val_inputs = {\n",
    "    \"features\": X_val[:,:,:],\n",
    "    \"dS\": dSt_val[:,:,:],\n",
    "    \"Z_T\": Z_T_val[:]\n",
    "}\n",
    "\n",
    "test_inputs = {\n",
    "    \"features\": X_test[:,:,:],\n",
    "    \"dS\": dSt_test[:,:,:],\n",
    "    \"Z_T\": Z_T_test[:]\n",
    "}\n",
    "\n",
    "input_label = np.zeros((n_train),dtype=np.float32)\n",
    "val_label = np.zeros((n_val),dtype=np.float32)\n",
    "test_label = np.zeros((n_test),dtype=np.float32)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = (tf.data.Dataset.from_tensor_slices((inputs, input_label))\n",
    "            .cache().shuffle(8192, seed=SEED, reshuffle_each_iteration=True)\n",
    "            .batch(BATCH).prefetch(AUTOTUNE))\n",
    "\n",
    "val_ds   = (tf.data.Dataset.from_tensor_slices((val_inputs, val_label))\n",
    "            .cache().batch(BATCH).prefetch(AUTOTUNE))\n",
    "\n",
    "test_ds  = (tf.data.Dataset.from_tensor_slices((test_inputs, test_label))\n",
    "            .batch(BATCH).prefetch(AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db49a91-1e5f-4efc-8579-2528221b8d6c",
   "metadata": {},
   "source": [
    "## 3.5) Zero-hedge baseline (validation)\n",
    "\n",
    "**What to do here:**\n",
    "- Baseline wealth if you **do not trade**: $(X^{(0)} = -Z_T)$.\n",
    "- Compute on **all** validation paths:\n",
    "  - `mean_baseline = mean(X0)`\n",
    "  - `VaR_α` and `CVaR_α` at `ALPHA` (note: sort ascending, take worst tail)\n",
    "- Log these numbers; they are your **reference** for how much the policy improves tail risk.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08fc1c1-da37-4ee7-9d4a-541b468a1911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_cvar_baseline: -31.621716\n",
      "val_mean_baseline: -7.653247\n",
      "val_p05_baseline: -29.537189\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5) Baseline \n",
    "# --------------------------\n",
    "wealth = - Z_T_val\n",
    "\n",
    "val_mean_baseline  = wealth.mean()\n",
    "sorted_wealth = np.sort(wealth)\n",
    "\n",
    "k = int(np.ceil((1 - ALPHA) * sorted_wealth.size))\n",
    "values = sorted_wealth[:k]\n",
    "\n",
    "val_cvar_baseline = values.mean()\n",
    "val_p05_baseline = np.percentile(wealth, 5)\n",
    "\n",
    "print(f\"val_cvar_baseline: {val_cvar_baseline:.6f}\")\n",
    "print(f\"val_mean_baseline: {val_mean_baseline:.6f}\")\n",
    "print(f\"val_p05_baseline: {val_p05_baseline:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541c9f4-8835-46f7-b17d-4ab00f516b9f",
   "metadata": {},
   "source": [
    "## 3.6) Policy network (backbone)\n",
    "\n",
    "**What to do here:**\n",
    "- Define three **Inputs**:\n",
    "  - `features`: `(n_steps, 4)` — the only tensor used by the policy\n",
    "  - `dS`: `(n_steps, 1)` — used *later* in rollout, not inside the policy\n",
    "  - `Z_T`: `()` — scalar terminal payoff, used *later* in rollout, not inside the policy\n",
    "- Build a small recurrent backbone, e.g. GRU→GRU→Dense:\n",
    "  - GRU(32, return_sequences=True) → GRU(16, return_sequences=True) → Dense(32, relu)\n",
    "  - Final Dense to 1 → raw position `a_raw(t)`\n",
    "  - **Clamp**: `a(t) = H_MAX * tanh(a_raw(t))` to bound $(|a_t|\\le H_{\\max})$\n",
    "\n",
    "**Why these choices:**\n",
    "- GRUs capture temporal context without heavy complexity.\n",
    "- `tanh` clamp stabilizes training, enforces realistic position bounds.\n",
    "- `dS` and `Z_T` must *not* leak into the policy — they are used only in P&L computation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00db88c7-8672-4048-87de-95e661664b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5691d57-47bc-4423-9fdc-7f1a7d2e48fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"policy_backbone\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " features (InputLayer)       [(None, 252, 4)]             0         []                            \n",
      "                                                                                                  \n",
      " gru_32 (GRU)                (None, 252, 32)              3648      ['features[0][0]']            \n",
      "                                                                                                  \n",
      " gru_16 (GRU)                (None, 252, 16)              2400      ['gru_32[0][0]']              \n",
      "                                                                                                  \n",
      " dense_32 (Dense)            (None, 252, 32)              544       ['gru_16[0][0]']              \n",
      "                                                                                                  \n",
      " a_raw (Dense)               (None, 252, 1)               33        ['dense_32[0][0]']            \n",
      "                                                                                                  \n",
      " dS (InputLayer)             [(None, 252, 1)]             0         []                            \n",
      "                                                                                                  \n",
      " Z_T (InputLayer)            [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " a (Lambda)                  (None, 252, 1)               0         ['a_raw[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6625 (25.88 KB)\n",
      "Trainable params: 6625 (25.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 6) Model\n",
    "# --------------------------\n",
    "\n",
    "features_in = keras.Input(shape=(n_steps, n_feat), name=\"features\")\n",
    "dS_in = keras.Input(shape=(n_steps,1), name=\"dS\")\n",
    "Z_T_in = keras.Input(shape=(), name=\"Z_T\")\n",
    "\n",
    "H = layers.GRU(32, return_sequences=True, name=\"gru_32\")(features_in)\n",
    "H = layers.GRU(16, return_sequences=True, name=\"gru_16\")(H)\n",
    "H = layers.Dense(32, activation=\"relu\", name=\"dense_32\")(H)\n",
    "\n",
    "a_raw = layers.Dense(1, name=\"a_raw\")(H)\n",
    "a = layers.Lambda(lambda z: tf.cast(H_MAX, z.dtype) * tf.tanh(z),name=\"a\")(a_raw)\n",
    "\n",
    "policy = keras.Model(inputs=[features_in, dS_in, Z_T_in], outputs=a, name=\"policy_backbone\")\n",
    "policy.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99fb6f-1035-4215-9e2d-99eaea705f81",
   "metadata": {},
   "source": [
    "## 3.7) Symbolic rollout (within the Keras graph)\n",
    "\n",
    "**What to do here (all tensor ops, no Python loops):**\n",
    "1. **Positions:** `a = policy(features)` → shape `(B, n_steps, 1)`\n",
    "2. **Turnover:** `a_prev` = shift of `a` with a zero at $(t=0)$;  \n",
    "   `turnover = |a - a_prev|`\n",
    "3. **Transaction cost:** get $(S_t)$ from features: `S_t = features[:,:,0] * S0` (then `[..., None]` to match dims);  \n",
    "   `cost = GAMMA * sum_t (S_t * turnover)` → shape `(B, 1)` then squeeze to `(B,)`\n",
    "4. **PnL:** `PnL = sum_t (a * dS)` → `(B,)`\n",
    "5. **Terminal wealth:** `X = -Z_T + PnL - cost` → `(B,)`\n",
    "\n",
    "**Monitoring tensors (for `add_metric`):**\n",
    "- `mean_X = mean(X)`\n",
    "- `mean_PnL = mean(PnL)`\n",
    "- `mean_cost = mean(cost)`\n",
    "- `turnover_mean = mean(turnover)` (averaged over batch & time)\n",
    "- `bound_frac = mean( I[|a| >= 0.95*H_MAX] )`\n",
    "- **Empirical tail stats on the batch** (for logging only):\n",
    "  - $(k = \\lceil (1-\\alpha)$,$\\text{batch\\_size} \\rceil)$\n",
    "  - `X_sorted = sort(X)` (ascending)\n",
    "  - `var_emp = X_sorted[k-1]`, `cvar_emp = mean(X_sorted[:k])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faac8bbb-92bb-4e25-a411-749346d0c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 7) Rollout\n",
    "# --------------------------\n",
    "\n",
    "a_prev = tf.concat([tf.zeros_like(a[:, :1, :]), a[:, :-1, :]],axis=1) \n",
    "turnover = tf.abs(a - a_prev)\n",
    "\n",
    "S_t = features_in[:, :, 0] * tf.cast(S0, tf.float32)   \n",
    "S_t = tf.expand_dims(S_t, axis=-1)                     \n",
    "\n",
    "cost = GAMMA * tf.reduce_sum(S_t * turnover, axis=1)\n",
    "\n",
    "PnL = tf.reduce_sum(a * dS_in, axis=1)\n",
    "\n",
    "X = -tf.expand_dims(Z_T_in, axis=-1) + PnL - cost\n",
    "X = tf.squeeze(X, axis=-1)\n",
    "\n",
    "mean_X = tf.reduce_mean(X)\n",
    "mean_PnL = tf.reduce_mean(tf.squeeze(PnL, -1))\n",
    "mean_cost = tf.reduce_mean(tf.squeeze(cost, -1))\n",
    "turnover_mu = tf.reduce_mean(turnover)  # average over batch & time\n",
    "bound_frac  = tf.reduce_mean(tf.cast(tf.abs(a) >= 0.95*H_MAX, tf.float32))\n",
    "\n",
    "k = tf.cast(tf.math.ceil((1.0 - ALPHA) * tf.cast(tf.shape(X)[0], tf.float32)), tf.int32)\n",
    "X_sorted = tf.sort(X)                # ascending = worse to better (since wealth; more negative = worse)\n",
    "var_emp = X_sorted[k-1]\n",
    "cvar_emp = tf.reduce_mean(X_sorted[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a61c0c-2892-49f2-9a2d-c74fb31e1ba1",
   "metadata": {},
   "source": [
    "## 3.8) RU CVaR head (loss layer)\n",
    "\n",
    "**What to do here:**\n",
    "- Add a custom layer **RUHead(α)** with a **trainable** scalar $(\\tau)$ (initialized e.g. near the baseline VaR or a constant):\n",
    "  $$\n",
    "  \\ell(X;\\tau) \\;=\\; \\frac{(\\tau - X)^+}{1-\\alpha} \\;-\\; \\tau\n",
    "  $$\n",
    "- Properties:\n",
    "  - Minimizing $( \\mathbb{E}[\\ell(X;\\tau)] )$ over $(\\tau)$ yields $(\\tau = \\text{VaR}_\\alpha(X))$.\n",
    "  - The minimized value equals $( \\text{CVaR}_\\alpha(X) )$.\n",
    "- Pipe the rollout wealth \\(X\\) into RUHead to get per-sample losses $(\\ell)$, then average.\n",
    "\n",
    "**Optional auxiliary penalty (keep small):**\n",
    "- $(\\beta \\cdot \\text{mean}(|X|))$ to nudge overall MAE down, but **do not** let it dominate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d308893-1efe-4f1c-8fd6-7125be322a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 8) CVaR head \n",
    "# --------------------------\n",
    "\n",
    "BETA = 0.01\n",
    "\n",
    "class RUHead(tf.keras.layers.Layer):\n",
    "    def __init__(self, alpha,tau_init=-10.0,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = float(alpha)\n",
    "        self.tau_init = float(tau_init)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.tau = self.add_weight(\n",
    "            name=\"tau\",\n",
    "            shape=(),\n",
    "            initializer=tf.keras.initializers.Constant(self.tau_init),\n",
    "            trainable=True,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    \n",
    "    def call(self, X):\n",
    "        X = tf.cast(X, self.tau.dtype)\n",
    "\n",
    "        if X.shape.rank == 2 and X.shape[-1] == 1:\n",
    "            X = tf.squeeze(X, axis=-1)\n",
    "            \n",
    "        hinge = tf.nn.relu(self.tau - X)\n",
    "        ell = hinge / (1.0 - self.alpha) - self.tau\n",
    "        self.add_metric(tf.identity(self.tau), name=\"tau\", aggregation=\"mean\")\n",
    "        return ell\n",
    "\n",
    "\n",
    "def identify_loss(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n",
    "ru = RUHead(alpha=ALPHA, name=\"ru_head\")\n",
    "ell = ru(X)\n",
    "mae_penalty = BETA * tf.reduce_mean(tf.abs(X))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da69e5-f1a9-407f-b247-2efb12fecaa3",
   "metadata": {},
   "source": [
    "## 3.9) Compose the training model\n",
    "\n",
    "**What to do here:**\n",
    "- Create `loss_model = Model([features_in, dS_in, Z_T_in] → RUHead(X))`.\n",
    "- Attach `add_metric(...)` for the monitors from §6 (mean_X, mean_PnL, mean_cost, turnover_mean, bound_frac, var_emp, cvar_emp) and also expose `tau` from RUHead.\n",
    "- If you include the MAE penalty, add it via `add_loss(β * mean(|X|))`.\n",
    "- **Compile** with Adam (`learning_rate = LR`, optional `clipnorm=1.0`).\n",
    "- Use an **identity loss** (`return y_pred`) because the RUHead already outputs $(\\ell)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0066b22b-374d-4978-abc9-3cd3375148fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 9) Loss Model\n",
    "# --------------------------\n",
    "\n",
    "loss_model = keras.Model(inputs=[features_in, dS_in, Z_T_in],\n",
    "                         outputs=ell,\n",
    "                         name=\"loss\")\n",
    "\n",
    "loss_model.add_loss(mae_penalty)\n",
    "\n",
    "loss_model.add_metric(mean_X, name=\"mean_X\", aggregation=\"mean\")\n",
    "loss_model.add_metric(mean_PnL, name=\"mean_PnL\", aggregation=\"mean\")\n",
    "loss_model.add_metric(mean_cost, name=\"mean_Cost\", aggregation=\"mean\")\n",
    "loss_model.add_metric(turnover_mu, name=\"turnover_mean\", aggregation=\"mean\")\n",
    "loss_model.add_metric(bound_frac, name=\"bound_frac\", aggregation=\"mean\")\n",
    "loss_model.add_metric(cvar_emp, name=\"cvar_emp\", aggregation=\"mean\")\n",
    "loss_model.add_metric(var_emp, name=\"var_emp\", aggregation=\"mean\")\n",
    "\n",
    "mean_abs_X = tf.reduce_mean(tf.abs(X))\n",
    "loss_model.add_metric(mean_abs_X, name=\"mean_abs_X\", aggregation=\"mean\")\n",
    "\n",
    "loss_model.compile(optimizer=keras.optimizers.Adam(learning_rate = LR,\n",
    "                                                   clipnorm=1.0),\n",
    "                                                   loss=identify_loss,\n",
    "                                                   )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cccce71-37d4-42e5-a260-f152576b3041",
   "metadata": {},
   "source": [
    "## 3.10) Training loop & callbacks\n",
    "\n",
    "**What to do here:**\n",
    "- Set callbacks:\n",
    "  - `ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5)`\n",
    "  - `EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)`\n",
    "  - `ModelCheckpoint(..., monitor=\"val_cvar_emp\", mode=\"min\")` to keep best tails\n",
    "  - `TerminateOnNaN()`\n",
    "- `fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=cbs)`\n",
    "- **How to read logs:**\n",
    "  - `loss / val_loss` ≈ batch mean of RU loss (proxy for CVaR)\n",
    "  - `tau` should settle near empirical VaR\n",
    "  - `cvar_emp` (val) should **decrease** vs baseline from §4\n",
    "  - `mean_cost`, `turnover_mean` give realism signals\n",
    "  - `bound_frac` near zero (not slamming into the clamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1596643b-ca6b-4138-98ad-1852aa47dce6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 18.9180 - tau: -10.0095 - mean_X: -7.5855 - mean_PnL: 0.1962 - mean_Cost: 0.0728 - turnover_mean: 0.0058 - bound_frac: 0.0000e+00 - cvar_emp: -16.0693 - var_emp: -13.6144 - mean_abs_X: 7.6014\n",
      "Epoch 1: val_cvar_emp improved from -inf to -14.63208, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 1: val_tau improved from -inf to -10.02001, saving model to results\\best_tail_by_var.weights.h5\n",
      "\n",
      "Epoch 1: val_mean_abs_X improved from inf to 7.66452, saving model to results\\best_center_by_absX.weights.h5\n",
      "20/20 [==============================] - 10s 356ms/step - loss: 18.9180 - tau: -10.0095 - mean_X: -7.5855 - mean_PnL: 0.1962 - mean_Cost: 0.0728 - turnover_mean: 0.0058 - bound_frac: 0.0000e+00 - cvar_emp: -16.0693 - var_emp: -13.6144 - mean_abs_X: 7.6014 - val_loss: 16.0748 - val_tau: -10.0200 - val_mean_X: -7.6600 - val_mean_PnL: 0.1012 - val_mean_Cost: 0.0945 - val_turnover_mean: 0.0075 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -14.6321 - val_var_emp: -12.2539 - val_mean_abs_X: 7.6645 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 15.2924 - tau: -10.0294 - mean_X: -7.6414 - mean_PnL: 0.1800 - mean_Cost: 0.1125 - turnover_mean: 0.0090 - bound_frac: 0.0000e+00 - cvar_emp: -14.0010 - var_emp: -12.0673 - mean_abs_X: 7.6492\n",
      "Epoch 2: val_cvar_emp improved from -14.63208 to -13.33692, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 2: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 2: val_mean_abs_X did not improve from 7.66452\n",
      "20/20 [==============================] - 7s 333ms/step - loss: 15.2924 - tau: -10.0294 - mean_X: -7.6414 - mean_PnL: 0.1800 - mean_Cost: 0.1125 - turnover_mean: 0.0090 - bound_frac: 0.0000e+00 - cvar_emp: -14.0010 - var_emp: -12.0673 - mean_abs_X: 7.6492 - val_loss: 14.6290 - val_tau: -10.0399 - val_mean_X: -7.6627 - val_mean_PnL: 0.1193 - val_mean_Cost: 0.1152 - val_turnover_mean: 0.0092 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -13.3369 - val_var_emp: -11.8405 - val_mean_abs_X: 7.6675 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 14.3402 - tau: -10.0494 - mean_X: -7.6590 - mean_PnL: 0.1624 - mean_Cost: 0.1125 - turnover_mean: 0.0090 - bound_frac: 0.0000e+00 - cvar_emp: -13.3449 - var_emp: -11.6544 - mean_abs_X: 7.6613\n",
      "Epoch 3: val_cvar_emp improved from -13.33692 to -12.62591, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 3: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 3: val_mean_abs_X did not improve from 7.66452\n",
      "20/20 [==============================] - 7s 336ms/step - loss: 14.3402 - tau: -10.0494 - mean_X: -7.6590 - mean_PnL: 0.1624 - mean_Cost: 0.1125 - turnover_mean: 0.0090 - bound_frac: 0.0000e+00 - cvar_emp: -13.3449 - var_emp: -11.6544 - mean_abs_X: 7.6613 - val_loss: 13.3718 - val_tau: -10.0599 - val_mean_X: -7.6665 - val_mean_PnL: 0.1157 - val_mean_Cost: 0.1154 - val_turnover_mean: 0.0092 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -12.6259 - val_var_emp: -11.1846 - val_mean_abs_X: 7.6676 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 13.4804 - tau: -10.0692 - mean_X: -7.6869 - mean_PnL: 0.1391 - mean_Cost: 0.1171 - turnover_mean: 0.0093 - bound_frac: 0.0000e+00 - cvar_emp: -12.8084 - var_emp: -11.2965 - mean_abs_X: 7.6871\n",
      "Epoch 4: val_cvar_emp improved from -12.62591 to -12.18350, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 4: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 4: val_mean_abs_X improved from 7.66452 to 7.66041, saving model to results\\best_center_by_absX.weights.h5\n",
      "20/20 [==============================] - 8s 397ms/step - loss: 13.4804 - tau: -10.0692 - mean_X: -7.6869 - mean_PnL: 0.1391 - mean_Cost: 0.1171 - turnover_mean: 0.0093 - bound_frac: 0.0000e+00 - cvar_emp: -12.8084 - var_emp: -11.2965 - mean_abs_X: 7.6871 - val_loss: 12.8625 - val_tau: -10.0793 - val_mean_X: -7.6603 - val_mean_PnL: 0.1280 - val_mean_Cost: 0.1215 - val_turnover_mean: 0.0096 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -12.1835 - val_var_emp: -11.0869 - val_mean_abs_X: 7.6604 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 12.7333 - tau: -10.0881 - mean_X: -7.6926 - mean_PnL: 0.1409 - mean_Cost: 0.1245 - turnover_mean: 0.0099 - bound_frac: 0.0000e+00 - cvar_emp: -12.2577 - var_emp: -10.9532 - mean_abs_X: 7.6926\n",
      "Epoch 5: val_cvar_emp did not improve from -12.18350\n",
      "\n",
      "Epoch 5: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 5: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 381ms/step - loss: 12.7333 - tau: -10.0881 - mean_X: -7.6926 - mean_PnL: 0.1409 - mean_Cost: 0.1245 - turnover_mean: 0.0099 - bound_frac: 0.0000e+00 - cvar_emp: -12.2577 - var_emp: -10.9532 - mean_abs_X: 7.6926 - val_loss: 13.0572 - val_tau: -10.0975 - val_mean_X: -7.6710 - val_mean_PnL: 0.1255 - val_mean_Cost: 0.1297 - val_turnover_mean: 0.0103 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -12.6459 - val_var_emp: -11.0783 - val_mean_abs_X: 7.6710 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 14.1909 - tau: -10.1059 - mean_X: -7.6988 - mean_PnL: 0.1488 - mean_Cost: 0.1387 - turnover_mean: 0.0110 - bound_frac: 0.0000e+00 - cvar_emp: -13.0890 - var_emp: -11.7254 - mean_abs_X: 7.7093\n",
      "Epoch 6: val_cvar_emp did not improve from -12.18350\n",
      "\n",
      "Epoch 6: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 6: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 7s 339ms/step - loss: 14.1909 - tau: -10.1059 - mean_X: -7.6988 - mean_PnL: 0.1488 - mean_Cost: 0.1387 - turnover_mean: 0.0110 - bound_frac: 0.0000e+00 - cvar_emp: -13.0890 - var_emp: -11.7254 - mean_abs_X: 7.7093 - val_loss: 16.7341 - val_tau: -10.1156 - val_mean_X: -7.6759 - val_mean_PnL: 0.1174 - val_mean_Cost: 0.1266 - val_turnover_mean: 0.0100 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -14.5802 - val_var_emp: -12.9475 - val_mean_abs_X: 7.6759 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 14.3780 - tau: -10.1244 - mean_X: -7.6976 - mean_PnL: 0.1501 - mean_Cost: 0.1388 - turnover_mean: 0.0110 - bound_frac: 0.0000e+00 - cvar_emp: -13.1094 - var_emp: -11.8441 - mean_abs_X: 7.7030\n",
      "Epoch 7: val_cvar_emp did not improve from -12.18350\n",
      "\n",
      "Epoch 7: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 7: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 7s 348ms/step - loss: 14.3780 - tau: -10.1244 - mean_X: -7.6976 - mean_PnL: 0.1501 - mean_Cost: 0.1388 - turnover_mean: 0.0110 - bound_frac: 0.0000e+00 - cvar_emp: -13.1094 - var_emp: -11.8441 - mean_abs_X: 7.7030 - val_loss: 13.9172 - val_tau: -10.1343 - val_mean_X: -7.6775 - val_mean_PnL: 0.1195 - val_mean_Cost: 0.1302 - val_turnover_mean: 0.0103 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -13.0835 - val_var_emp: -11.6078 - val_mean_abs_X: 7.6775 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 12.5503 - tau: -10.1424 - mean_X: -7.7220 - mean_PnL: 0.1260 - mean_Cost: 0.1391 - turnover_mean: 0.0110 - bound_frac: 0.0000e+00 - cvar_emp: -12.1607 - var_emp: -10.9715 - mean_abs_X: 7.7256\n",
      "Epoch 8: val_cvar_emp improved from -12.18350 to -12.08095, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 8: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 8: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 7s 365ms/step - loss: 12.5503 - tau: -10.1424 - mean_X: -7.7220 - mean_PnL: 0.1260 - mean_Cost: 0.1391 - turnover_mean: 0.0110 - bound_frac: 0.0000e+00 - cvar_emp: -12.1607 - var_emp: -10.9715 - mean_abs_X: 7.7256 - val_loss: 12.3224 - val_tau: -10.1504 - val_mean_X: -7.6806 - val_mean_PnL: 0.1271 - val_mean_Cost: 0.1410 - val_turnover_mean: 0.0111 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -12.0809 - val_var_emp: -10.7347 - val_mean_abs_X: 7.6817 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 12.4812 - tau: -10.1567 - mean_X: -7.7183 - mean_PnL: 0.1411 - mean_Cost: 0.1505 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -12.0627 - var_emp: -10.9419 - mean_abs_X: 7.7266\n",
      "Epoch 9: val_cvar_emp improved from -12.08095 to -11.47584, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 9: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 9: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 12.4812 - tau: -10.1567 - mean_X: -7.7183 - mean_PnL: 0.1411 - mean_Cost: 0.1505 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -12.0627 - var_emp: -10.9419 - mean_abs_X: 7.7266 - val_loss: 11.7018 - val_tau: -10.1637 - val_mean_X: -7.6796 - val_mean_PnL: 0.1432 - val_mean_Cost: 0.1561 - val_turnover_mean: 0.0124 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.4758 - val_var_emp: -10.5853 - val_mean_abs_X: 7.6827 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.7077 - tau: -10.1690 - mean_X: -7.7256 - mean_PnL: 0.1374 - mean_Cost: 0.1541 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.5497 - var_emp: -10.4759 - mean_abs_X: 7.7326\n",
      "Epoch 10: val_cvar_emp improved from -11.47584 to -11.43016, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 10: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 10: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 441ms/step - loss: 11.7077 - tau: -10.1690 - mean_X: -7.7256 - mean_PnL: 0.1374 - mean_Cost: 0.1541 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.5497 - var_emp: -10.4759 - mean_abs_X: 7.7326 - val_loss: 11.6162 - val_tau: -10.1740 - val_mean_X: -7.6769 - val_mean_PnL: 0.1425 - val_mean_Cost: 0.1527 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.4302 - val_var_emp: -10.5227 - val_mean_abs_X: 7.6810 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.6335 - tau: -10.1772 - mean_X: -7.7262 - mean_PnL: 0.1363 - mean_Cost: 0.1536 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.5168 - var_emp: -10.4226 - mean_abs_X: 7.7337\n",
      "Epoch 11: val_cvar_emp improved from -11.43016 to -11.34943, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 11: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 11: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 405ms/step - loss: 11.6335 - tau: -10.1772 - mean_X: -7.7262 - mean_PnL: 0.1363 - mean_Cost: 0.1536 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.5168 - var_emp: -10.4226 - mean_abs_X: 7.7337 - val_loss: 11.4901 - val_tau: -10.1803 - val_mean_X: -7.6868 - val_mean_PnL: 0.1357 - val_mean_Cost: 0.1558 - val_turnover_mean: 0.0123 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.3494 - val_var_emp: -10.4104 - val_mean_abs_X: 7.6911 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.6162 - tau: -10.1834 - mean_X: -7.7366 - mean_PnL: 0.1295 - mean_Cost: 0.1572 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.4979 - var_emp: -10.4292 - mean_abs_X: 7.7451\n",
      "Epoch 12: val_cvar_emp improved from -11.34943 to -11.32250, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 12: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 12: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 429ms/step - loss: 11.6162 - tau: -10.1834 - mean_X: -7.7366 - mean_PnL: 0.1295 - mean_Cost: 0.1572 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.4979 - var_emp: -10.4292 - mean_abs_X: 7.7451 - val_loss: 11.4549 - val_tau: -10.1870 - val_mean_X: -7.6869 - val_mean_PnL: 0.1388 - val_mean_Cost: 0.1589 - val_turnover_mean: 0.0126 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.3225 - val_var_emp: -10.3576 - val_mean_abs_X: 7.6922 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5711 - tau: -10.1897 - mean_X: -7.7359 - mean_PnL: 0.1312 - mean_Cost: 0.1581 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.4583 - var_emp: -10.3750 - mean_abs_X: 7.7426\n",
      "Epoch 13: val_cvar_emp improved from -11.32250 to -11.28758, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 13: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 13: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 11.5711 - tau: -10.1897 - mean_X: -7.7359 - mean_PnL: 0.1312 - mean_Cost: 0.1581 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.4583 - var_emp: -10.3750 - mean_abs_X: 7.7426 - val_loss: 11.4035 - val_tau: -10.1925 - val_mean_X: -7.6929 - val_mean_PnL: 0.1346 - val_mean_Cost: 0.1608 - val_turnover_mean: 0.0127 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.2876 - val_var_emp: -10.3222 - val_mean_abs_X: 7.6975 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5496 - tau: -10.1948 - mean_X: -7.7364 - mean_PnL: 0.1326 - mean_Cost: 0.1601 - turnover_mean: 0.0127 - bound_frac: 0.0000e+00 - cvar_emp: -11.4336 - var_emp: -10.3983 - mean_abs_X: 7.7466\n",
      "Epoch 14: val_cvar_emp did not improve from -11.28758\n",
      "\n",
      "Epoch 14: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 14: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 406ms/step - loss: 11.5496 - tau: -10.1948 - mean_X: -7.7364 - mean_PnL: 0.1326 - mean_Cost: 0.1601 - turnover_mean: 0.0127 - bound_frac: 0.0000e+00 - cvar_emp: -11.4336 - var_emp: -10.3983 - mean_abs_X: 7.7466 - val_loss: 11.4610 - val_tau: -10.1977 - val_mean_X: -7.6873 - val_mean_PnL: 0.1396 - val_mean_Cost: 0.1601 - val_turnover_mean: 0.0127 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.3184 - val_var_emp: -10.4051 - val_mean_abs_X: 7.6924 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5752 - tau: -10.2008 - mean_X: -7.7384 - mean_PnL: 0.1286 - mean_Cost: 0.1581 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.4372 - var_emp: -10.4137 - mean_abs_X: 7.7470\n",
      "Epoch 15: val_cvar_emp improved from -11.28758 to -11.20347, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 15: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 15: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 429ms/step - loss: 11.5752 - tau: -10.2008 - mean_X: -7.7384 - mean_PnL: 0.1286 - mean_Cost: 0.1581 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.4372 - var_emp: -10.4137 - mean_abs_X: 7.7470 - val_loss: 11.3254 - val_tau: -10.2041 - val_mean_X: -7.6825 - val_mean_PnL: 0.1409 - val_mean_Cost: 0.1567 - val_turnover_mean: 0.0124 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.2035 - val_var_emp: -10.2845 - val_mean_abs_X: 7.6863 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 12.0475 - tau: -10.2088 - mean_X: -7.7422 - mean_PnL: 0.1275 - mean_Cost: 0.1608 - turnover_mean: 0.0127 - bound_frac: 0.0000e+00 - cvar_emp: -11.7978 - var_emp: -10.6861 - mean_abs_X: 7.7504\n",
      "Epoch 16: val_cvar_emp did not improve from -11.20347\n",
      "\n",
      "Epoch 16: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 16: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 12.0475 - tau: -10.2088 - mean_X: -7.7422 - mean_PnL: 0.1275 - mean_Cost: 0.1608 - turnover_mean: 0.0127 - bound_frac: 0.0000e+00 - cvar_emp: -11.7978 - var_emp: -10.6861 - mean_abs_X: 7.7504 - val_loss: 12.6670 - val_tau: -10.2141 - val_mean_X: -7.6822 - val_mean_PnL: 0.1486 - val_mean_Cost: 0.1641 - val_turnover_mean: 0.0130 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -12.0821 - val_var_emp: -11.1806 - val_mean_abs_X: 7.6918 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 12.0085 - tau: -10.2197 - mean_X: -7.7244 - mean_PnL: 0.1432 - mean_Cost: 0.1587 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.7365 - var_emp: -10.6917 - mean_abs_X: 7.7365\n",
      "Epoch 17: val_cvar_emp did not improve from -11.20347\n",
      "\n",
      "Epoch 17: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 17: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 12.0085 - tau: -10.2197 - mean_X: -7.7244 - mean_PnL: 0.1432 - mean_Cost: 0.1587 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.7365 - var_emp: -10.6917 - mean_abs_X: 7.7365 - val_loss: 11.6868 - val_tau: -10.2259 - val_mean_X: -7.6848 - val_mean_PnL: 0.1344 - val_mean_Cost: 0.1525 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.5532 - val_var_emp: -10.4148 - val_mean_abs_X: 7.6866 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.9023 - tau: -10.2313 - mean_X: -7.7464 - mean_PnL: 0.1209 - mean_Cost: 0.1584 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.7393 - var_emp: -10.5711 - mean_abs_X: 7.7535\n",
      "Epoch 18: val_cvar_emp improved from -11.20347 to -11.19886, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 18: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 18: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 449ms/step - loss: 11.9023 - tau: -10.2313 - mean_X: -7.7464 - mean_PnL: 0.1209 - mean_Cost: 0.1584 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.7393 - var_emp: -10.5711 - mean_abs_X: 7.7535 - val_loss: 11.3203 - val_tau: -10.2367 - val_mean_X: -7.6850 - val_mean_PnL: 0.1397 - val_mean_Cost: 0.1579 - val_turnover_mean: 0.0125 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.1989 - val_var_emp: -10.2244 - val_mean_abs_X: 7.6880 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.7759 - tau: -10.2420 - mean_X: -7.7224 - mean_PnL: 0.1457 - mean_Cost: 0.1591 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.6154 - var_emp: -10.5764 - mean_abs_X: 7.7286\n",
      "Epoch 19: val_cvar_emp did not improve from -11.19886\n",
      "\n",
      "Epoch 19: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 19: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 437ms/step - loss: 11.7759 - tau: -10.2420 - mean_X: -7.7224 - mean_PnL: 0.1457 - mean_Cost: 0.1591 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.6154 - var_emp: -10.5764 - mean_abs_X: 7.7286 - val_loss: 11.4715 - val_tau: -10.2476 - val_mean_X: -7.6991 - val_mean_PnL: 0.1270 - val_mean_Cost: 0.1594 - val_turnover_mean: 0.0126 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.3580 - val_var_emp: -10.2433 - val_mean_abs_X: 7.7027 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.7652 - tau: -10.2513 - mean_X: -7.7231 - mean_PnL: 0.1452 - mean_Cost: 0.1593 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.6037 - var_emp: -10.5107 - mean_abs_X: 7.7334\n",
      "Epoch 20: val_cvar_emp did not improve from -11.19886\n",
      "\n",
      "Epoch 20: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 20: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 11.7652 - tau: -10.2513 - mean_X: -7.7231 - mean_PnL: 0.1452 - mean_Cost: 0.1593 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.6037 - var_emp: -10.5107 - mean_abs_X: 7.7334 - val_loss: 11.6168 - val_tau: -10.2559 - val_mean_X: -7.6906 - val_mean_PnL: 0.1371 - val_mean_Cost: 0.1610 - val_turnover_mean: 0.0127 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.5011 - val_var_emp: -10.4187 - val_mean_abs_X: 7.6978 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.7887 - tau: -10.2594 - mean_X: -7.7425 - mean_PnL: 0.1259 - mean_Cost: 0.1595 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.6248 - var_emp: -10.5726 - mean_abs_X: 7.7486\n",
      "Epoch 21: val_cvar_emp did not improve from -11.19886\n",
      "\n",
      "Epoch 21: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 21: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 439ms/step - loss: 11.7887 - tau: -10.2594 - mean_X: -7.7425 - mean_PnL: 0.1259 - mean_Cost: 0.1595 - turnover_mean: 0.0126 - bound_frac: 0.0000e+00 - cvar_emp: -11.6248 - var_emp: -10.5726 - mean_abs_X: 7.7486 - val_loss: 11.6498 - val_tau: -10.2640 - val_mean_X: -7.6940 - val_mean_PnL: 0.1367 - val_mean_Cost: 0.1640 - val_turnover_mean: 0.0130 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.4964 - val_var_emp: -10.5706 - val_mean_abs_X: 7.6990 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.7650 - tau: -10.2686 - mean_X: -7.7325 - mean_PnL: 0.1398 - mean_Cost: 0.1634 - turnover_mean: 0.0129 - bound_frac: 0.0000e+00 - cvar_emp: -11.6009 - var_emp: -10.5245 - mean_abs_X: 7.7413\n",
      "Epoch 22: val_cvar_emp did not improve from -11.19886\n",
      "\n",
      "Epoch 22: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 22: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 429ms/step - loss: 11.7650 - tau: -10.2686 - mean_X: -7.7325 - mean_PnL: 0.1398 - mean_Cost: 0.1634 - turnover_mean: 0.0129 - bound_frac: 0.0000e+00 - cvar_emp: -11.6009 - var_emp: -10.5245 - mean_abs_X: 7.7413 - val_loss: 11.4942 - val_tau: -10.2730 - val_mean_X: -7.6926 - val_mean_PnL: 0.1363 - val_mean_Cost: 0.1622 - val_turnover_mean: 0.0128 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.3651 - val_var_emp: -10.4691 - val_mean_abs_X: 7.6971 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.6772 - tau: -10.2772 - mean_X: -7.7329 - mean_PnL: 0.1365 - mean_Cost: 0.1605 - turnover_mean: 0.0127 - bound_frac: 0.0000e+00 - cvar_emp: -11.5264 - var_emp: -10.4549 - mean_abs_X: 7.7409\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: val_cvar_emp did not improve from -11.19886\n",
      "\n",
      "Epoch 23: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 23: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 432ms/step - loss: 11.6772 - tau: -10.2772 - mean_X: -7.7329 - mean_PnL: 0.1365 - mean_Cost: 0.1605 - turnover_mean: 0.0127 - bound_frac: 0.0000e+00 - cvar_emp: -11.5264 - var_emp: -10.4549 - mean_abs_X: 7.7409 - val_loss: 11.9350 - val_tau: -10.2817 - val_mean_X: -7.6962 - val_mean_PnL: 0.1254 - val_mean_Cost: 0.1548 - val_turnover_mean: 0.0122 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.7798 - val_var_emp: -10.5994 - val_mean_abs_X: 7.6976 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.7160 - tau: -10.2838 - mean_X: -7.7426 - mean_PnL: 0.1248 - mean_Cost: 0.1585 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.5547 - var_emp: -10.5134 - mean_abs_X: 7.7513\n",
      "Epoch 24: val_cvar_emp did not improve from -11.19886\n",
      "\n",
      "Epoch 24: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 24: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 11.7160 - tau: -10.2838 - mean_X: -7.7426 - mean_PnL: 0.1248 - mean_Cost: 0.1585 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.5547 - var_emp: -10.5134 - mean_abs_X: 7.7513 - val_loss: 11.5353 - val_tau: -10.2861 - val_mean_X: -7.6976 - val_mean_PnL: 0.1270 - val_mean_Cost: 0.1578 - val_turnover_mean: 0.0125 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.4166 - val_var_emp: -10.4274 - val_mean_abs_X: 7.7017 - lr: 5.0000e-04\n",
      "Epoch 25/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5870 - tau: -10.2877 - mean_X: -7.7322 - mean_PnL: 0.1338 - mean_Cost: 0.1571 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.4660 - var_emp: -10.4016 - mean_abs_X: 7.7353\n",
      "Epoch 25: val_cvar_emp improved from -11.19886 to -11.11395, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 25: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 25: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 438ms/step - loss: 11.5870 - tau: -10.2877 - mean_X: -7.7322 - mean_PnL: 0.1338 - mean_Cost: 0.1571 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.4660 - var_emp: -10.4016 - mean_abs_X: 7.7353 - val_loss: 11.2529 - val_tau: -10.2893 - val_mean_X: -7.6968 - val_mean_PnL: 0.1269 - val_mean_Cost: 0.1570 - val_turnover_mean: 0.0124 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.1139 - val_var_emp: -10.0837 - val_mean_abs_X: 7.6995 - lr: 5.0000e-04\n",
      "Epoch 26/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5942 - tau: -10.2899 - mean_X: -7.7191 - mean_PnL: 0.1476 - mean_Cost: 0.1578 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.4782 - var_emp: -10.4123 - mean_abs_X: 7.7240\n",
      "Epoch 26: val_cvar_emp did not improve from -11.11395\n",
      "\n",
      "Epoch 26: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 26: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 438ms/step - loss: 11.5942 - tau: -10.2899 - mean_X: -7.7191 - mean_PnL: 0.1476 - mean_Cost: 0.1578 - turnover_mean: 0.0125 - bound_frac: 0.0000e+00 - cvar_emp: -11.4782 - var_emp: -10.4123 - mean_abs_X: 7.7240 - val_loss: 11.4940 - val_tau: -10.2908 - val_mean_X: -7.6839 - val_mean_PnL: 0.1383 - val_mean_Cost: 0.1555 - val_turnover_mean: 0.0123 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.3394 - val_var_emp: -10.5315 - val_mean_abs_X: 7.6868 - lr: 5.0000e-04\n",
      "Epoch 27/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.3698 - tau: -10.2920 - mean_X: -7.7321 - mean_PnL: 0.1317 - mean_Cost: 0.1549 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.2716 - var_emp: -10.2696 - mean_abs_X: 7.7362\n",
      "Epoch 27: val_cvar_emp improved from -11.11395 to -11.09534, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 27: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 27: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 430ms/step - loss: 11.3698 - tau: -10.2920 - mean_X: -7.7321 - mean_PnL: 0.1317 - mean_Cost: 0.1549 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.2716 - var_emp: -10.2696 - mean_abs_X: 7.7362 - val_loss: 11.2332 - val_tau: -10.2924 - val_mean_X: -7.6905 - val_mean_PnL: 0.1292 - val_mean_Cost: 0.1530 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.0953 - val_var_emp: -10.0849 - val_mean_abs_X: 7.6927 - lr: 5.0000e-04\n",
      "Epoch 28/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.4105 - tau: -10.2923 - mean_X: -7.7201 - mean_PnL: 0.1423 - mean_Cost: 0.1534 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.3249 - var_emp: -10.3198 - mean_abs_X: 7.7238\n",
      "Epoch 28: val_cvar_emp did not improve from -11.09534\n",
      "\n",
      "Epoch 28: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 28: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 414ms/step - loss: 11.4105 - tau: -10.2923 - mean_X: -7.7201 - mean_PnL: 0.1423 - mean_Cost: 0.1534 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.3249 - var_emp: -10.3198 - mean_abs_X: 7.7238 - val_loss: 11.9949 - val_tau: -10.2924 - val_mean_X: -7.6921 - val_mean_PnL: 0.1221 - val_mean_Cost: 0.1475 - val_turnover_mean: 0.0117 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.8082 - val_var_emp: -10.7006 - val_mean_abs_X: 7.6926 - lr: 5.0000e-04\n",
      "Epoch 29/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.6123 - tau: -10.2938 - mean_X: -7.7082 - mean_PnL: 0.1497 - mean_Cost: 0.1490 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.4832 - var_emp: -10.4932 - mean_abs_X: 7.7114\n",
      "Epoch 29: val_cvar_emp did not improve from -11.09534\n",
      "\n",
      "Epoch 29: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 29: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 429ms/step - loss: 11.6123 - tau: -10.2938 - mean_X: -7.7082 - mean_PnL: 0.1497 - mean_Cost: 0.1490 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.4832 - var_emp: -10.4932 - mean_abs_X: 7.7114 - val_loss: 11.3577 - val_tau: -10.2958 - val_mean_X: -7.6886 - val_mean_PnL: 0.1307 - val_mean_Cost: 0.1525 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.2544 - val_var_emp: -10.3200 - val_mean_abs_X: 7.6913 - lr: 5.0000e-04\n",
      "Epoch 30/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5918 - tau: -10.2973 - mean_X: -7.7195 - mean_PnL: 0.1451 - mean_Cost: 0.1557 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.4318 - var_emp: -10.4774 - mean_abs_X: 7.7236\n",
      "Epoch 30: val_cvar_emp improved from -11.09534 to -11.06843, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 30: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 30: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 430ms/step - loss: 11.5918 - tau: -10.2973 - mean_X: -7.7195 - mean_PnL: 0.1451 - mean_Cost: 0.1557 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.4318 - var_emp: -10.4774 - mean_abs_X: 7.7236 - val_loss: 11.2107 - val_tau: -10.2991 - val_mean_X: -7.6881 - val_mean_PnL: 0.1310 - val_mean_Cost: 0.1524 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.0684 - val_var_emp: -10.0714 - val_mean_abs_X: 7.6898 - lr: 5.0000e-04\n",
      "Epoch 31/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.4285 - tau: -10.3008 - mean_X: -7.7148 - mean_PnL: 0.1444 - mean_Cost: 0.1503 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.3176 - var_emp: -10.3544 - mean_abs_X: 7.7180\n",
      "Epoch 31: val_cvar_emp did not improve from -11.06843\n",
      "\n",
      "Epoch 31: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 31: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 431ms/step - loss: 11.4285 - tau: -10.3008 - mean_X: -7.7148 - mean_PnL: 0.1444 - mean_Cost: 0.1503 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.3176 - var_emp: -10.3544 - mean_abs_X: 7.7180 - val_loss: 11.9806 - val_tau: -10.3017 - val_mean_X: -7.6892 - val_mean_PnL: 0.1320 - val_mean_Cost: 0.1545 - val_turnover_mean: 0.0123 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.7184 - val_var_emp: -10.8242 - val_mean_abs_X: 7.6930 - lr: 5.0000e-04\n",
      "Epoch 32/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5174 - tau: -10.3026 - mean_X: -7.7138 - mean_PnL: 0.1499 - mean_Cost: 0.1548 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.4016 - var_emp: -10.4128 - mean_abs_X: 7.7180\n",
      "Epoch 32: val_cvar_emp did not improve from -11.06843\n",
      "\n",
      "Epoch 32: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 32: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 11.5174 - tau: -10.3026 - mean_X: -7.7138 - mean_PnL: 0.1499 - mean_Cost: 0.1548 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.4016 - var_emp: -10.4128 - mean_abs_X: 7.7180 - val_loss: 11.2659 - val_tau: -10.3034 - val_mean_X: -7.6883 - val_mean_PnL: 0.1321 - val_mean_Cost: 0.1537 - val_turnover_mean: 0.0122 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.1234 - val_var_emp: -10.1045 - val_mean_abs_X: 7.6896 - lr: 5.0000e-04\n",
      "Epoch 33/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.3677 - tau: -10.3036 - mean_X: -7.7352 - mean_PnL: 0.1296 - mean_Cost: 0.1558 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.2781 - var_emp: -10.2853 - mean_abs_X: 7.7366\n",
      "Epoch 33: val_cvar_emp did not improve from -11.06843\n",
      "\n",
      "Epoch 33: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 33: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 11.3677 - tau: -10.3036 - mean_X: -7.7352 - mean_PnL: 0.1296 - mean_Cost: 0.1558 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.2781 - var_emp: -10.2853 - mean_abs_X: 7.7366 - val_loss: 11.2720 - val_tau: -10.3036 - val_mean_X: -7.6973 - val_mean_PnL: 0.1273 - val_mean_Cost: 0.1578 - val_turnover_mean: 0.0125 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.1357 - val_var_emp: -10.1146 - val_mean_abs_X: 7.6985 - lr: 5.0000e-04\n",
      "Epoch 34/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.3462 - tau: -10.3035 - mean_X: -7.7325 - mean_PnL: 0.1327 - mean_Cost: 0.1563 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.2474 - var_emp: -10.2883 - mean_abs_X: 7.7351\n",
      "Epoch 34: val_cvar_emp improved from -11.06843 to -11.02057, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 34: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 34: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 432ms/step - loss: 11.3462 - tau: -10.3035 - mean_X: -7.7325 - mean_PnL: 0.1327 - mean_Cost: 0.1563 - turnover_mean: 0.0124 - bound_frac: 0.0000e+00 - cvar_emp: -11.2474 - var_emp: -10.2883 - mean_abs_X: 7.7351 - val_loss: 11.1702 - val_tau: -10.3033 - val_mean_X: -7.6927 - val_mean_PnL: 0.1274 - val_mean_Cost: 0.1533 - val_turnover_mean: 0.0122 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.0206 - val_var_emp: -10.0438 - val_mean_abs_X: 7.6941 - lr: 5.0000e-04\n",
      "Epoch 35/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.2486 - tau: -10.3025 - mean_X: -7.7232 - mean_PnL: 0.1374 - mean_Cost: 0.1517 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.1539 - var_emp: -10.1999 - mean_abs_X: 7.7246\n",
      "Epoch 35: val_cvar_emp did not improve from -11.02057\n",
      "\n",
      "Epoch 35: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 35: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 11.2486 - tau: -10.3025 - mean_X: -7.7232 - mean_PnL: 0.1374 - mean_Cost: 0.1517 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.1539 - var_emp: -10.1999 - mean_abs_X: 7.7246 - val_loss: 11.1691 - val_tau: -10.3017 - val_mean_X: -7.6884 - val_mean_PnL: 0.1289 - val_mean_Cost: 0.1506 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.0340 - val_var_emp: -10.0860 - val_mean_abs_X: 7.6900 - lr: 5.0000e-04\n",
      "Epoch 36/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5756 - tau: -10.3020 - mean_X: -7.7141 - mean_PnL: 0.1449 - mean_Cost: 0.1501 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.4538 - var_emp: -10.4432 - mean_abs_X: 7.7170\n",
      "Epoch 36: val_cvar_emp did not improve from -11.02057\n",
      "\n",
      "Epoch 36: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 36: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 11.5756 - tau: -10.3020 - mean_X: -7.7141 - mean_PnL: 0.1449 - mean_Cost: 0.1501 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.4538 - var_emp: -10.4432 - mean_abs_X: 7.7170 - val_loss: 12.5079 - val_tau: -10.3030 - val_mean_X: -7.6792 - val_mean_PnL: 0.1408 - val_mean_Cost: 0.1533 - val_turnover_mean: 0.0122 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -12.0617 - val_var_emp: -11.1736 - val_mean_abs_X: 7.6834 - lr: 5.0000e-04\n",
      "Epoch 37/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.5534 - tau: -10.3047 - mean_X: -7.7217 - mean_PnL: 0.1361 - mean_Cost: 0.1488 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.4058 - var_emp: -10.4302 - mean_abs_X: 7.7242\n",
      "Epoch 37: val_cvar_emp did not improve from -11.02057\n",
      "\n",
      "Epoch 37: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 37: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 11.5534 - tau: -10.3047 - mean_X: -7.7217 - mean_PnL: 0.1361 - mean_Cost: 0.1488 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.4058 - var_emp: -10.4302 - mean_abs_X: 7.7242 - val_loss: 11.2978 - val_tau: -10.3057 - val_mean_X: -7.6909 - val_mean_PnL: 0.1222 - val_mean_Cost: 0.1464 - val_turnover_mean: 0.0116 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.1778 - val_var_emp: -10.1813 - val_mean_abs_X: 7.6916 - lr: 5.0000e-04\n",
      "Epoch 38/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.3601 - tau: -10.3056 - mean_X: -7.7219 - mean_PnL: 0.1378 - mean_Cost: 0.1507 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.2583 - var_emp: -10.2818 - mean_abs_X: 7.7254\n",
      "Epoch 38: val_cvar_emp did not improve from -11.02057\n",
      "\n",
      "Epoch 38: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 38: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 11.3601 - tau: -10.3056 - mean_X: -7.7219 - mean_PnL: 0.1378 - mean_Cost: 0.1507 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.2583 - var_emp: -10.2818 - mean_abs_X: 7.7254 - val_loss: 11.3769 - val_tau: -10.3055 - val_mean_X: -7.6890 - val_mean_PnL: 0.1225 - val_mean_Cost: 0.1448 - val_turnover_mean: 0.0115 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.2629 - val_var_emp: -10.2469 - val_mean_abs_X: 7.6896 - lr: 5.0000e-04\n",
      "Epoch 39/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.4828 - tau: -10.3059 - mean_X: -7.7219 - mean_PnL: 0.1356 - mean_Cost: 0.1486 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.3804 - var_emp: -10.3746 - mean_abs_X: 7.7236\n",
      "Epoch 39: val_cvar_emp did not improve from -11.02057\n",
      "\n",
      "Epoch 39: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 39: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 404ms/step - loss: 11.4828 - tau: -10.3059 - mean_X: -7.7219 - mean_PnL: 0.1356 - mean_Cost: 0.1486 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.3804 - var_emp: -10.3746 - mean_abs_X: 7.7236 - val_loss: 11.4915 - val_tau: -10.3065 - val_mean_X: -7.6821 - val_mean_PnL: 0.1353 - val_mean_Cost: 0.1506 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.3606 - val_var_emp: -10.5036 - val_mean_abs_X: 7.6846 - lr: 5.0000e-04\n",
      "Epoch 40/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.4654 - tau: -10.3069 - mean_X: -7.7222 - mean_PnL: 0.1359 - mean_Cost: 0.1492 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.3466 - var_emp: -10.3444 - mean_abs_X: 7.7244\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 40: val_cvar_emp did not improve from -11.02057\n",
      "\n",
      "Epoch 40: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 40: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 436ms/step - loss: 11.4654 - tau: -10.3069 - mean_X: -7.7222 - mean_PnL: 0.1359 - mean_Cost: 0.1492 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.3466 - var_emp: -10.3444 - mean_abs_X: 7.7244 - val_loss: 11.3792 - val_tau: -10.3076 - val_mean_X: -7.6840 - val_mean_PnL: 0.1299 - val_mean_Cost: 0.1471 - val_turnover_mean: 0.0116 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.2461 - val_var_emp: -10.1656 - val_mean_abs_X: 7.6846 - lr: 5.0000e-04\n",
      "Epoch 41/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.2661 - tau: -10.3075 - mean_X: -7.7128 - mean_PnL: 0.1447 - mean_Cost: 0.1486 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.1594 - var_emp: -10.1901 - mean_abs_X: 7.7157\n",
      "Epoch 41: val_cvar_emp improved from -11.02057 to -10.94197, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 41: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 41: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 11.2661 - tau: -10.3075 - mean_X: -7.7128 - mean_PnL: 0.1447 - mean_Cost: 0.1486 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.1594 - var_emp: -10.1901 - mean_abs_X: 7.7157 - val_loss: 11.0900 - val_tau: -10.3071 - val_mean_X: -7.6829 - val_mean_PnL: 0.1300 - val_mean_Cost: 0.1461 - val_turnover_mean: 0.0116 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9420 - val_var_emp: -10.0515 - val_mean_abs_X: 7.6840 - lr: 2.5000e-04\n",
      "Epoch 42/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.2713 - tau: -10.3064 - mean_X: -7.7135 - mean_PnL: 0.1425 - mean_Cost: 0.1472 - turnover_mean: 0.0117 - bound_frac: 0.0000e+00 - cvar_emp: -11.1687 - var_emp: -10.2083 - mean_abs_X: 7.7151\n",
      "Epoch 42: val_cvar_emp did not improve from -10.94197\n",
      "\n",
      "Epoch 42: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 42: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 11.2713 - tau: -10.3064 - mean_X: -7.7135 - mean_PnL: 0.1425 - mean_Cost: 0.1472 - turnover_mean: 0.0117 - bound_frac: 0.0000e+00 - cvar_emp: -11.1687 - var_emp: -10.2083 - mean_abs_X: 7.7151 - val_loss: 11.1142 - val_tau: -10.3058 - val_mean_X: -7.6853 - val_mean_PnL: 0.1282 - val_mean_Cost: 0.1467 - val_turnover_mean: 0.0116 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9488 - val_var_emp: -9.9829 - val_mean_abs_X: 7.6862 - lr: 2.5000e-04\n",
      "Epoch 43/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1821 - tau: -10.3050 - mean_X: -7.7208 - mean_PnL: 0.1385 - mean_Cost: 0.1504 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.0573 - var_emp: -10.1414 - mean_abs_X: 7.7224\n",
      "Epoch 43: val_cvar_emp did not improve from -10.94197\n",
      "\n",
      "Epoch 43: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 43: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 412ms/step - loss: 11.1821 - tau: -10.3050 - mean_X: -7.7208 - mean_PnL: 0.1385 - mean_Cost: 0.1504 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.0573 - var_emp: -10.1414 - mean_abs_X: 7.7224 - val_loss: 11.2012 - val_tau: -10.3042 - val_mean_X: -7.6875 - val_mean_PnL: 0.1268 - val_mean_Cost: 0.1475 - val_turnover_mean: 0.0117 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.0505 - val_var_emp: -10.0504 - val_mean_abs_X: 7.6880 - lr: 2.5000e-04\n",
      "Epoch 44/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.3137 - tau: -10.3035 - mean_X: -7.7348 - mean_PnL: 0.1265 - mean_Cost: 0.1524 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.2016 - var_emp: -10.2321 - mean_abs_X: 7.7359\n",
      "Epoch 44: val_cvar_emp did not improve from -10.94197\n",
      "\n",
      "Epoch 44: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 44: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 11.3137 - tau: -10.3035 - mean_X: -7.7348 - mean_PnL: 0.1265 - mean_Cost: 0.1524 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.2016 - var_emp: -10.2321 - mean_abs_X: 7.7359 - val_loss: 11.2689 - val_tau: -10.3029 - val_mean_X: -7.6920 - val_mean_PnL: 0.1226 - val_mean_Cost: 0.1478 - val_turnover_mean: 0.0117 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.1371 - val_var_emp: -10.0982 - val_mean_abs_X: 7.6923 - lr: 2.5000e-04\n",
      "Epoch 45/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.2046 - tau: -10.3025 - mean_X: -7.7265 - mean_PnL: 0.1323 - mean_Cost: 0.1499 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.1069 - var_emp: -10.1777 - mean_abs_X: 7.7267\n",
      "Epoch 45: val_cvar_emp did not improve from -10.94197\n",
      "\n",
      "Epoch 45: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 45: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 414ms/step - loss: 11.2046 - tau: -10.3025 - mean_X: -7.7265 - mean_PnL: 0.1323 - mean_Cost: 0.1499 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.1069 - var_emp: -10.1777 - mean_abs_X: 7.7267 - val_loss: 11.2629 - val_tau: -10.3019 - val_mean_X: -7.6946 - val_mean_PnL: 0.1265 - val_mean_Cost: 0.1543 - val_turnover_mean: 0.0123 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.1581 - val_var_emp: -10.2463 - val_mean_abs_X: 7.6967 - lr: 2.5000e-04\n",
      "Epoch 46/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1981 - tau: -10.3012 - mean_X: -7.7236 - mean_PnL: 0.1387 - mean_Cost: 0.1534 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.0901 - var_emp: -10.1364 - mean_abs_X: 7.7250\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 46: val_cvar_emp did not improve from -10.94197\n",
      "\n",
      "Epoch 46: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 46: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 11.1981 - tau: -10.3012 - mean_X: -7.7236 - mean_PnL: 0.1387 - mean_Cost: 0.1534 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.0901 - var_emp: -10.1364 - mean_abs_X: 7.7250 - val_loss: 11.1919 - val_tau: -10.3002 - val_mean_X: -7.6963 - val_mean_PnL: 0.1186 - val_mean_Cost: 0.1481 - val_turnover_mean: 0.0117 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.0565 - val_var_emp: -10.0995 - val_mean_abs_X: 7.6966 - lr: 2.5000e-04\n",
      "Epoch 47/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.2114 - tau: -10.2998 - mean_X: -7.7227 - mean_PnL: 0.1377 - mean_Cost: 0.1515 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.1076 - var_emp: -10.1523 - mean_abs_X: 7.7233\n",
      "Epoch 47: val_cvar_emp improved from -10.94197 to -10.89351, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 47: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 47: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 11.2114 - tau: -10.2998 - mean_X: -7.7227 - mean_PnL: 0.1377 - mean_Cost: 0.1515 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.1076 - var_emp: -10.1523 - mean_abs_X: 7.7233 - val_loss: 11.0668 - val_tau: -10.2993 - val_mean_X: -7.6902 - val_mean_PnL: 0.1291 - val_mean_Cost: 0.1525 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8935 - val_var_emp: -9.9710 - val_mean_abs_X: 7.6912 - lr: 1.2500e-04\n",
      "Epoch 48/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1611 - tau: -10.2989 - mean_X: -7.7257 - mean_PnL: 0.1337 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0541 - var_emp: -10.1570 - mean_abs_X: 7.7268\n",
      "Epoch 48: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 48: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 48: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 11.1611 - tau: -10.2989 - mean_X: -7.7257 - mean_PnL: 0.1337 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0541 - var_emp: -10.1570 - mean_abs_X: 7.7268 - val_loss: 11.0873 - val_tau: -10.2985 - val_mean_X: -7.6919 - val_mean_PnL: 0.1253 - val_mean_Cost: 0.1504 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9084 - val_var_emp: -9.9404 - val_mean_abs_X: 7.6926 - lr: 1.2500e-04\n",
      "Epoch 49/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1806 - tau: -10.2981 - mean_X: -7.7278 - mean_PnL: 0.1323 - mean_Cost: 0.1512 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0743 - var_emp: -10.1069 - mean_abs_X: 7.7287\n",
      "Epoch 49: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 49: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 49: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 11.1806 - tau: -10.2981 - mean_X: -7.7278 - mean_PnL: 0.1323 - mean_Cost: 0.1512 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0743 - var_emp: -10.1069 - mean_abs_X: 7.7287 - val_loss: 11.0686 - val_tau: -10.2975 - val_mean_X: -7.6903 - val_mean_PnL: 0.1270 - val_mean_Cost: 0.1506 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9176 - val_var_emp: -10.0338 - val_mean_abs_X: 7.6911 - lr: 1.2500e-04\n",
      "Epoch 50/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1589 - tau: -10.2970 - mean_X: -7.7273 - mean_PnL: 0.1316 - mean_Cost: 0.1500 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.0584 - var_emp: -10.1430 - mean_abs_X: 7.7273\n",
      "Epoch 50: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 50: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 50: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 11.1589 - tau: -10.2970 - mean_X: -7.7273 - mean_PnL: 0.1316 - mean_Cost: 0.1500 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.0584 - var_emp: -10.1430 - mean_abs_X: 7.7273 - val_loss: 11.0684 - val_tau: -10.2964 - val_mean_X: -7.6900 - val_mean_PnL: 0.1242 - val_mean_Cost: 0.1475 - val_turnover_mean: 0.0117 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9157 - val_var_emp: -10.0371 - val_mean_abs_X: 7.6901 - lr: 1.2500e-04\n",
      "Epoch 51/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1510 - tau: -10.2960 - mean_X: -7.7241 - mean_PnL: 0.1351 - mean_Cost: 0.1503 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0464 - var_emp: -10.1627 - mean_abs_X: 7.7244\n",
      "Epoch 51: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 51: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 51: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 439ms/step - loss: 11.1510 - tau: -10.2960 - mean_X: -7.7241 - mean_PnL: 0.1351 - mean_Cost: 0.1503 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0464 - var_emp: -10.1627 - mean_abs_X: 7.7244 - val_loss: 11.0546 - val_tau: -10.2955 - val_mean_X: -7.6902 - val_mean_PnL: 0.1278 - val_mean_Cost: 0.1513 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9019 - val_var_emp: -10.0274 - val_mean_abs_X: 7.6909 - lr: 1.2500e-04\n",
      "Epoch 52/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1424 - tau: -10.2950 - mean_X: -7.7280 - mean_PnL: 0.1336 - mean_Cost: 0.1527 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0316 - var_emp: -10.0868 - mean_abs_X: 7.7284\n",
      "Epoch 52: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 52: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 52: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 11.1424 - tau: -10.2950 - mean_X: -7.7280 - mean_PnL: 0.1336 - mean_Cost: 0.1527 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0316 - var_emp: -10.0868 - mean_abs_X: 7.7284 - val_loss: 11.0839 - val_tau: -10.2943 - val_mean_X: -7.6933 - val_mean_PnL: 0.1243 - val_mean_Cost: 0.1509 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9308 - val_var_emp: -10.0257 - val_mean_abs_X: 7.6941 - lr: 1.2500e-04\n",
      "Epoch 53/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1540 - tau: -10.2937 - mean_X: -7.7225 - mean_PnL: 0.1353 - mean_Cost: 0.1489 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.0521 - var_emp: -10.1494 - mean_abs_X: 7.7228\n",
      "Epoch 53: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 53: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 53: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 403ms/step - loss: 11.1540 - tau: -10.2937 - mean_X: -7.7225 - mean_PnL: 0.1353 - mean_Cost: 0.1489 - turnover_mean: 0.0118 - bound_frac: 0.0000e+00 - cvar_emp: -11.0521 - var_emp: -10.1494 - mean_abs_X: 7.7228 - val_loss: 11.0665 - val_tau: -10.2931 - val_mean_X: -7.6919 - val_mean_PnL: 0.1261 - val_mean_Cost: 0.1513 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9131 - val_var_emp: -10.0336 - val_mean_abs_X: 7.6927 - lr: 1.2500e-04\n",
      "Epoch 54/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1560 - tau: -10.2926 - mean_X: -7.7271 - mean_PnL: 0.1329 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0503 - var_emp: -10.1317 - mean_abs_X: 7.7277\n",
      "Epoch 54: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 54: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 54: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 11.1560 - tau: -10.2926 - mean_X: -7.7271 - mean_PnL: 0.1329 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0503 - var_emp: -10.1317 - mean_abs_X: 7.7277 - val_loss: 11.1169 - val_tau: -10.2920 - val_mean_X: -7.6863 - val_mean_PnL: 0.1305 - val_mean_Cost: 0.1501 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9481 - val_var_emp: -9.9876 - val_mean_abs_X: 7.6864 - lr: 1.2500e-04\n",
      "Epoch 55/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1950 - tau: -10.2917 - mean_X: -7.7290 - mean_PnL: 0.1328 - mean_Cost: 0.1529 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.0907 - var_emp: -10.1512 - mean_abs_X: 7.7296\n",
      "Epoch 55: val_cvar_emp did not improve from -10.89351\n",
      "\n",
      "Epoch 55: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 55: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 406ms/step - loss: 11.1950 - tau: -10.2917 - mean_X: -7.7290 - mean_PnL: 0.1328 - mean_Cost: 0.1529 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -11.0907 - var_emp: -10.1512 - mean_abs_X: 7.7296 - val_loss: 11.0522 - val_tau: -10.2912 - val_mean_X: -7.6891 - val_mean_PnL: 0.1288 - val_mean_Cost: 0.1511 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8963 - val_var_emp: -10.0272 - val_mean_abs_X: 7.6897 - lr: 1.2500e-04\n",
      "Epoch 56/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1840 - tau: -10.2908 - mean_X: -7.7255 - mean_PnL: 0.1343 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0829 - var_emp: -10.1493 - mean_abs_X: 7.7263\n",
      "Epoch 56: val_cvar_emp improved from -10.89351 to -10.87823, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 56: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 56: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 407ms/step - loss: 11.1840 - tau: -10.2908 - mean_X: -7.7255 - mean_PnL: 0.1343 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -11.0829 - var_emp: -10.1493 - mean_abs_X: 7.7263 - val_loss: 11.0679 - val_tau: -10.2903 - val_mean_X: -7.6933 - val_mean_PnL: 0.1244 - val_mean_Cost: 0.1509 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8782 - val_var_emp: -9.9338 - val_mean_abs_X: 7.6939 - lr: 1.2500e-04\n",
      "Epoch 57/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1532 - tau: -10.2898 - mean_X: -7.7232 - mean_PnL: 0.1374 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0436 - var_emp: -10.0931 - mean_abs_X: 7.7243\n",
      "Epoch 57: val_cvar_emp did not improve from -10.87823\n",
      "\n",
      "Epoch 57: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 57: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 11.1532 - tau: -10.2898 - mean_X: -7.7232 - mean_PnL: 0.1374 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0436 - var_emp: -10.0931 - mean_abs_X: 7.7243 - val_loss: 11.1419 - val_tau: -10.2892 - val_mean_X: -7.6896 - val_mean_PnL: 0.1264 - val_mean_Cost: 0.1492 - val_turnover_mean: 0.0118 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9704 - val_var_emp: -9.9654 - val_mean_abs_X: 7.6896 - lr: 1.2500e-04\n",
      "Epoch 58/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1319 - tau: -10.2886 - mean_X: -7.7199 - mean_PnL: 0.1409 - mean_Cost: 0.1519 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0152 - var_emp: -10.1051 - mean_abs_X: 7.7207\n",
      "Epoch 58: val_cvar_emp did not improve from -10.87823\n",
      "\n",
      "Epoch 58: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 58: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 387ms/step - loss: 11.1319 - tau: -10.2886 - mean_X: -7.7199 - mean_PnL: 0.1409 - mean_Cost: 0.1519 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0152 - var_emp: -10.1051 - mean_abs_X: 7.7207 - val_loss: 11.0545 - val_tau: -10.2879 - val_mean_X: -7.6872 - val_mean_PnL: 0.1298 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9199 - val_var_emp: -10.0790 - val_mean_abs_X: 7.6876 - lr: 1.2500e-04\n",
      "Epoch 59/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1062 - tau: -10.2873 - mean_X: -7.7242 - mean_PnL: 0.1356 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9948 - var_emp: -10.0799 - mean_abs_X: 7.7245\n",
      "Epoch 59: val_cvar_emp did not improve from -10.87823\n",
      "\n",
      "Epoch 59: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 59: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 433ms/step - loss: 11.1062 - tau: -10.2873 - mean_X: -7.7242 - mean_PnL: 0.1356 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9948 - var_emp: -10.0799 - mean_abs_X: 7.7245 - val_loss: 11.0360 - val_tau: -10.2866 - val_mean_X: -7.6893 - val_mean_PnL: 0.1268 - val_mean_Cost: 0.1493 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8897 - val_var_emp: -10.0389 - val_mean_abs_X: 7.6896 - lr: 1.2500e-04\n",
      "Epoch 60/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0972 - tau: -10.2858 - mean_X: -7.7246 - mean_PnL: 0.1342 - mean_Cost: 0.1499 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9940 - var_emp: -10.1213 - mean_abs_X: 7.7250\n",
      "Epoch 60: val_cvar_emp improved from -10.87823 to -10.86806, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 60: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 60: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 429ms/step - loss: 11.0972 - tau: -10.2858 - mean_X: -7.7246 - mean_PnL: 0.1342 - mean_Cost: 0.1499 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9940 - var_emp: -10.1213 - mean_abs_X: 7.7250 - val_loss: 11.0400 - val_tau: -10.2851 - val_mean_X: -7.6908 - val_mean_PnL: 0.1270 - val_mean_Cost: 0.1510 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8681 - val_var_emp: -9.9705 - val_mean_abs_X: 7.6912 - lr: 1.2500e-04\n",
      "Epoch 61/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1027 - tau: -10.2843 - mean_X: -7.7207 - mean_PnL: 0.1397 - mean_Cost: 0.1515 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9821 - var_emp: -10.0488 - mean_abs_X: 7.7210\n",
      "Epoch 61: val_cvar_emp did not improve from -10.86806\n",
      "\n",
      "Epoch 61: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 61: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 429ms/step - loss: 11.1027 - tau: -10.2843 - mean_X: -7.7207 - mean_PnL: 0.1397 - mean_Cost: 0.1515 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9821 - var_emp: -10.0488 - mean_abs_X: 7.7210 - val_loss: 11.0625 - val_tau: -10.2835 - val_mean_X: -7.6873 - val_mean_PnL: 0.1310 - val_mean_Cost: 0.1515 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8810 - val_var_emp: -9.9222 - val_mean_abs_X: 7.6874 - lr: 1.2500e-04\n",
      "Epoch 62/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0971 - tau: -10.2828 - mean_X: -7.7313 - mean_PnL: 0.1296 - mean_Cost: 0.1519 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9841 - var_emp: -10.0837 - mean_abs_X: 7.7313\n",
      "Epoch 62: val_cvar_emp improved from -10.86806 to -10.85934, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 62: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 62: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 431ms/step - loss: 11.0971 - tau: -10.2828 - mean_X: -7.7313 - mean_PnL: 0.1296 - mean_Cost: 0.1519 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9841 - var_emp: -10.0837 - mean_abs_X: 7.7313 - val_loss: 11.0421 - val_tau: -10.2821 - val_mean_X: -7.6908 - val_mean_PnL: 0.1276 - val_mean_Cost: 0.1516 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8593 - val_var_emp: -9.9119 - val_mean_abs_X: 7.6909 - lr: 1.2500e-04\n",
      "Epoch 63/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0832 - tau: -10.2813 - mean_X: -7.7219 - mean_PnL: 0.1382 - mean_Cost: 0.1512 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9745 - var_emp: -10.0949 - mean_abs_X: 7.7221\n",
      "Epoch 63: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 63: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 63: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 11.0832 - tau: -10.2813 - mean_X: -7.7219 - mean_PnL: 0.1382 - mean_Cost: 0.1512 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9745 - var_emp: -10.0949 - mean_abs_X: 7.7221 - val_loss: 11.0306 - val_tau: -10.2806 - val_mean_X: -7.6914 - val_mean_PnL: 0.1257 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8597 - val_var_emp: -9.9704 - val_mean_abs_X: 7.6914 - lr: 1.2500e-04\n",
      "Epoch 64/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1270 - tau: -10.2799 - mean_X: -7.7268 - mean_PnL: 0.1343 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0133 - var_emp: -10.1228 - mean_abs_X: 7.7268\n",
      "Epoch 64: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 64: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 64: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 402ms/step - loss: 11.1270 - tau: -10.2799 - mean_X: -7.7268 - mean_PnL: 0.1343 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0133 - var_emp: -10.1228 - mean_abs_X: 7.7268 - val_loss: 11.1093 - val_tau: -10.2792 - val_mean_X: -7.6912 - val_mean_PnL: 0.1277 - val_mean_Cost: 0.1522 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9955 - val_var_emp: -10.1753 - val_mean_abs_X: 7.6918 - lr: 1.2500e-04\n",
      "Epoch 65/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0838 - tau: -10.2786 - mean_X: -7.7224 - mean_PnL: 0.1375 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9783 - var_emp: -10.0946 - mean_abs_X: 7.7224\n",
      "Epoch 65: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 65: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 65: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 406ms/step - loss: 11.0838 - tau: -10.2786 - mean_X: -7.7224 - mean_PnL: 0.1375 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9783 - var_emp: -10.0946 - mean_abs_X: 7.7224 - val_loss: 11.0367 - val_tau: -10.2779 - val_mean_X: -7.6928 - val_mean_PnL: 0.1231 - val_mean_Cost: 0.1491 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8830 - val_var_emp: -9.9984 - val_mean_abs_X: 7.6928 - lr: 1.2500e-04\n",
      "Epoch 66/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1428 - tau: -10.2772 - mean_X: -7.7286 - mean_PnL: 0.1299 - mean_Cost: 0.1496 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.0395 - var_emp: -10.1580 - mean_abs_X: 7.7286\n",
      "Epoch 66: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 66: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 66: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 11.1428 - tau: -10.2772 - mean_X: -7.7286 - mean_PnL: 0.1299 - mean_Cost: 0.1496 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -11.0395 - var_emp: -10.1580 - mean_abs_X: 7.7286 - val_loss: 11.0529 - val_tau: -10.2765 - val_mean_X: -7.6878 - val_mean_PnL: 0.1294 - val_mean_Cost: 0.1505 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8896 - val_var_emp: -9.9684 - val_mean_abs_X: 7.6878 - lr: 1.2500e-04\n",
      "Epoch 67/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1364 - tau: -10.2759 - mean_X: -7.7292 - mean_PnL: 0.1337 - mean_Cost: 0.1540 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.0228 - var_emp: -10.1223 - mean_abs_X: 7.7295\n",
      "Epoch 67: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 67: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 67: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 398ms/step - loss: 11.1364 - tau: -10.2759 - mean_X: -7.7292 - mean_PnL: 0.1337 - mean_Cost: 0.1540 - turnover_mean: 0.0123 - bound_frac: 0.0000e+00 - cvar_emp: -11.0228 - var_emp: -10.1223 - mean_abs_X: 7.7295 - val_loss: 11.0783 - val_tau: -10.2753 - val_mean_X: -7.6920 - val_mean_PnL: 0.1264 - val_mean_Cost: 0.1516 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9027 - val_var_emp: -9.9463 - val_mean_abs_X: 7.6920 - lr: 1.2500e-04\n",
      "Epoch 68/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0993 - tau: -10.2746 - mean_X: -7.7239 - mean_PnL: 0.1367 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9936 - var_emp: -10.1129 - mean_abs_X: 7.7239\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 68: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 68: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 68: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 391ms/step - loss: 11.0993 - tau: -10.2746 - mean_X: -7.7239 - mean_PnL: 0.1367 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9936 - var_emp: -10.1129 - mean_abs_X: 7.7239 - val_loss: 11.1465 - val_tau: -10.2739 - val_mean_X: -7.6910 - val_mean_PnL: 0.1245 - val_mean_Cost: 0.1488 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -11.0146 - val_var_emp: -10.1202 - val_mean_abs_X: 7.6910 - lr: 1.2500e-04\n",
      "Epoch 69/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0929 - tau: -10.2737 - mean_X: -7.7286 - mean_PnL: 0.1324 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9873 - var_emp: -10.1036 - mean_abs_X: 7.7286\n",
      "Epoch 69: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 69: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 69: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 382ms/step - loss: 11.0929 - tau: -10.2737 - mean_X: -7.7286 - mean_PnL: 0.1324 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9873 - var_emp: -10.1036 - mean_abs_X: 7.7286 - val_loss: 11.0425 - val_tau: -10.2734 - val_mean_X: -7.6920 - val_mean_PnL: 0.1280 - val_mean_Cost: 0.1533 - val_turnover_mean: 0.0122 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.9047 - val_var_emp: -10.0551 - val_mean_abs_X: 7.6923 - lr: 6.2500e-05\n",
      "Epoch 70/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0818 - tau: -10.2730 - mean_X: -7.7249 - mean_PnL: 0.1368 - mean_Cost: 0.1527 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9759 - var_emp: -10.0975 - mean_abs_X: 7.7250\n",
      "Epoch 70: val_cvar_emp did not improve from -10.85934\n",
      "\n",
      "Epoch 70: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 70: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 11.0818 - tau: -10.2730 - mean_X: -7.7249 - mean_PnL: 0.1368 - mean_Cost: 0.1527 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9759 - var_emp: -10.0975 - mean_abs_X: 7.7250 - val_loss: 11.0187 - val_tau: -10.2726 - val_mean_X: -7.6927 - val_mean_PnL: 0.1255 - val_mean_Cost: 0.1514 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8756 - val_var_emp: -10.0233 - val_mean_abs_X: 7.6927 - lr: 6.2500e-05\n",
      "Epoch 71/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0694 - tau: -10.2722 - mean_X: -7.7276 - mean_PnL: 0.1346 - mean_Cost: 0.1533 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9570 - var_emp: -10.0745 - mean_abs_X: 7.7276\n",
      "Epoch 71: val_cvar_emp improved from -10.85934 to -10.83523, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 71: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 71: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 11.0694 - tau: -10.2722 - mean_X: -7.7276 - mean_PnL: 0.1346 - mean_Cost: 0.1533 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9570 - var_emp: -10.0745 - mean_abs_X: 7.7276 - val_loss: 11.0035 - val_tau: -10.2718 - val_mean_X: -7.6912 - val_mean_PnL: 0.1279 - val_mean_Cost: 0.1523 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8352 - val_var_emp: -9.9653 - val_mean_abs_X: 7.6912 - lr: 6.2500e-05\n",
      "Epoch 72/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0852 - tau: -10.2714 - mean_X: -7.7299 - mean_PnL: 0.1301 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9796 - var_emp: -10.0945 - mean_abs_X: 7.7299\n",
      "Epoch 72: val_cvar_emp did not improve from -10.83523\n",
      "\n",
      "Epoch 72: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 72: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 11.0852 - tau: -10.2714 - mean_X: -7.7299 - mean_PnL: 0.1301 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9796 - var_emp: -10.0945 - mean_abs_X: 7.7299 - val_loss: 11.0117 - val_tau: -10.2710 - val_mean_X: -7.6912 - val_mean_PnL: 0.1248 - val_mean_Cost: 0.1492 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8499 - val_var_emp: -9.9876 - val_mean_abs_X: 7.6912 - lr: 6.2500e-05\n",
      "Epoch 73/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0845 - tau: -10.2707 - mean_X: -7.7257 - mean_PnL: 0.1348 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9796 - var_emp: -10.1129 - mean_abs_X: 7.7257\n",
      "Epoch 73: val_cvar_emp did not improve from -10.83523\n",
      "\n",
      "Epoch 73: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 73: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 11.0845 - tau: -10.2707 - mean_X: -7.7257 - mean_PnL: 0.1348 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9796 - var_emp: -10.1129 - mean_abs_X: 7.7257 - val_loss: 11.0084 - val_tau: -10.2704 - val_mean_X: -7.6918 - val_mean_PnL: 0.1269 - val_mean_Cost: 0.1519 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8542 - val_var_emp: -9.9967 - val_mean_abs_X: 7.6918 - lr: 6.2500e-05\n",
      "Epoch 74/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0522 - tau: -10.2700 - mean_X: -7.7250 - mean_PnL: 0.1366 - mean_Cost: 0.1526 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9340 - var_emp: -10.0618 - mean_abs_X: 7.7250\n",
      "Epoch 74: val_cvar_emp did not improve from -10.83523\n",
      "\n",
      "Epoch 74: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 74: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 391ms/step - loss: 11.0522 - tau: -10.2700 - mean_X: -7.7250 - mean_PnL: 0.1366 - mean_Cost: 0.1526 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9340 - var_emp: -10.0618 - mean_abs_X: 7.7250 - val_loss: 11.0102 - val_tau: -10.2695 - val_mean_X: -7.6894 - val_mean_PnL: 0.1305 - val_mean_Cost: 0.1531 - val_turnover_mean: 0.0122 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8619 - val_var_emp: -10.0136 - val_mean_abs_X: 7.6895 - lr: 6.2500e-05\n",
      "Epoch 75/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0539 - tau: -10.2691 - mean_X: -7.7252 - mean_PnL: 0.1366 - mean_Cost: 0.1529 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9383 - var_emp: -10.0520 - mean_abs_X: 7.7252\n",
      "Epoch 75: val_cvar_emp did not improve from -10.83523\n",
      "\n",
      "Epoch 75: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 75: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 400ms/step - loss: 11.0539 - tau: -10.2691 - mean_X: -7.7252 - mean_PnL: 0.1366 - mean_Cost: 0.1529 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9383 - var_emp: -10.0520 - mean_abs_X: 7.7252 - val_loss: 11.0084 - val_tau: -10.2687 - val_mean_X: -7.6907 - val_mean_PnL: 0.1264 - val_mean_Cost: 0.1504 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8353 - val_var_emp: -9.9468 - val_mean_abs_X: 7.6907 - lr: 6.2500e-05\n",
      "Epoch 76/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0566 - tau: -10.2682 - mean_X: -7.7230 - mean_PnL: 0.1359 - mean_Cost: 0.1500 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9510 - var_emp: -10.0982 - mean_abs_X: 7.7230\n",
      "Epoch 76: val_cvar_emp improved from -10.83523 to -10.83058, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 76: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 76: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 11.0566 - tau: -10.2682 - mean_X: -7.7230 - mean_PnL: 0.1359 - mean_Cost: 0.1500 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9510 - var_emp: -10.0982 - mean_abs_X: 7.7230 - val_loss: 11.0017 - val_tau: -10.2678 - val_mean_X: -7.6930 - val_mean_PnL: 0.1244 - val_mean_Cost: 0.1506 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8306 - val_var_emp: -9.9520 - val_mean_abs_X: 7.6930 - lr: 6.2500e-05\n",
      "Epoch 77/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0639 - tau: -10.2674 - mean_X: -7.7269 - mean_PnL: 0.1347 - mean_Cost: 0.1527 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9465 - var_emp: -10.0584 - mean_abs_X: 7.7269\n",
      "Epoch 77: val_cvar_emp improved from -10.83058 to -10.82791, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 77: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 77: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 11.0639 - tau: -10.2674 - mean_X: -7.7269 - mean_PnL: 0.1347 - mean_Cost: 0.1527 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9465 - var_emp: -10.0584 - mean_abs_X: 7.7269 - val_loss: 11.0143 - val_tau: -10.2669 - val_mean_X: -7.6917 - val_mean_PnL: 0.1266 - val_mean_Cost: 0.1516 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8279 - val_var_emp: -9.8905 - val_mean_abs_X: 7.6917 - lr: 6.2500e-05\n",
      "Epoch 78/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.1096 - tau: -10.2665 - mean_X: -7.7184 - mean_PnL: 0.1423 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0013 - var_emp: -10.0803 - mean_abs_X: 7.7186\n",
      "Epoch 78: val_cvar_emp did not improve from -10.82791\n",
      "\n",
      "Epoch 78: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 78: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 400ms/step - loss: 11.1096 - tau: -10.2665 - mean_X: -7.7184 - mean_PnL: 0.1423 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -11.0013 - var_emp: -10.0803 - mean_abs_X: 7.7186 - val_loss: 11.0158 - val_tau: -10.2661 - val_mean_X: -7.6925 - val_mean_PnL: 0.1244 - val_mean_Cost: 0.1501 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8334 - val_var_emp: -9.9121 - val_mean_abs_X: 7.6925 - lr: 6.2500e-05\n",
      "Epoch 79/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0670 - tau: -10.2658 - mean_X: -7.7230 - mean_PnL: 0.1368 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9589 - var_emp: -10.0827 - mean_abs_X: 7.7230\n",
      "Epoch 79: val_cvar_emp did not improve from -10.82791\n",
      "\n",
      "Epoch 79: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 79: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 399ms/step - loss: 11.0670 - tau: -10.2658 - mean_X: -7.7230 - mean_PnL: 0.1368 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9589 - var_emp: -10.0827 - mean_abs_X: 7.7230 - val_loss: 11.0125 - val_tau: -10.2654 - val_mean_X: -7.6889 - val_mean_PnL: 0.1277 - val_mean_Cost: 0.1498 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8802 - val_var_emp: -10.0477 - val_mean_abs_X: 7.6889 - lr: 6.2500e-05\n",
      "Epoch 80/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0620 - tau: -10.2650 - mean_X: -7.7227 - mean_PnL: 0.1363 - mean_Cost: 0.1501 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9562 - var_emp: -10.0872 - mean_abs_X: 7.7227\n",
      "Epoch 80: val_cvar_emp improved from -10.82791 to -10.82522, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 80: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 80: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 11.0620 - tau: -10.2650 - mean_X: -7.7227 - mean_PnL: 0.1363 - mean_Cost: 0.1501 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9562 - var_emp: -10.0872 - mean_abs_X: 7.7227 - val_loss: 11.0064 - val_tau: -10.2646 - val_mean_X: -7.6907 - val_mean_PnL: 0.1259 - val_mean_Cost: 0.1499 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8252 - val_var_emp: -9.9136 - val_mean_abs_X: 7.6907 - lr: 6.2500e-05\n",
      "Epoch 81/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0471 - tau: -10.2641 - mean_X: -7.7237 - mean_PnL: 0.1370 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9236 - var_emp: -10.0235 - mean_abs_X: 7.7237\n",
      "Epoch 81: val_cvar_emp did not improve from -10.82522\n",
      "\n",
      "Epoch 81: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 81: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 11.0471 - tau: -10.2641 - mean_X: -7.7237 - mean_PnL: 0.1370 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9236 - var_emp: -10.0235 - mean_abs_X: 7.7237 - val_loss: 10.9989 - val_tau: -10.2637 - val_mean_X: -7.6876 - val_mean_PnL: 0.1308 - val_mean_Cost: 0.1517 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8265 - val_var_emp: -9.9355 - val_mean_abs_X: 7.6876 - lr: 6.2500e-05\n",
      "Epoch 82/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0430 - tau: -10.2632 - mean_X: -7.7221 - mean_PnL: 0.1363 - mean_Cost: 0.1495 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9328 - var_emp: -10.0682 - mean_abs_X: 7.7221\n",
      "Epoch 82: val_cvar_emp did not improve from -10.82522\n",
      "\n",
      "Epoch 82: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 82: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 11.0430 - tau: -10.2632 - mean_X: -7.7221 - mean_PnL: 0.1363 - mean_Cost: 0.1495 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9328 - var_emp: -10.0682 - mean_abs_X: 7.7221 - val_loss: 10.9922 - val_tau: -10.2628 - val_mean_X: -7.6891 - val_mean_PnL: 0.1253 - val_mean_Cost: 0.1476 - val_turnover_mean: 0.0118 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8295 - val_var_emp: -9.9644 - val_mean_abs_X: 7.6891 - lr: 6.2500e-05\n",
      "Epoch 83/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0485 - tau: -10.2623 - mean_X: -7.7254 - mean_PnL: 0.1337 - mean_Cost: 0.1502 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9206 - var_emp: -10.0449 - mean_abs_X: 7.7254\n",
      "Epoch 83: val_cvar_emp did not improve from -10.82522\n",
      "\n",
      "Epoch 83: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 83: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 11.0485 - tau: -10.2623 - mean_X: -7.7254 - mean_PnL: 0.1337 - mean_Cost: 0.1502 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9206 - var_emp: -10.0449 - mean_abs_X: 7.7254 - val_loss: 10.9880 - val_tau: -10.2618 - val_mean_X: -7.6887 - val_mean_PnL: 0.1283 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8254 - val_var_emp: -9.9527 - val_mean_abs_X: 7.6887 - lr: 6.2500e-05\n",
      "Epoch 84/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0676 - tau: -10.2614 - mean_X: -7.7232 - mean_PnL: 0.1363 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9621 - var_emp: -10.1045 - mean_abs_X: 7.7233\n",
      "Epoch 84: val_cvar_emp did not improve from -10.82522\n",
      "\n",
      "Epoch 84: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 84: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 11.0676 - tau: -10.2614 - mean_X: -7.7232 - mean_PnL: 0.1363 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9621 - var_emp: -10.1045 - mean_abs_X: 7.7233 - val_loss: 11.0003 - val_tau: -10.2610 - val_mean_X: -7.6889 - val_mean_PnL: 0.1279 - val_mean_Cost: 0.1500 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8559 - val_var_emp: -10.0121 - val_mean_abs_X: 7.6889 - lr: 6.2500e-05\n",
      "Epoch 85/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0487 - tau: -10.2606 - mean_X: -7.7231 - mean_PnL: 0.1364 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9298 - var_emp: -10.0391 - mean_abs_X: 7.7231\n",
      "Epoch 85: val_cvar_emp improved from -10.82522 to -10.81598, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 85: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 85: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 405ms/step - loss: 11.0487 - tau: -10.2606 - mean_X: -7.7231 - mean_PnL: 0.1364 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9298 - var_emp: -10.0391 - mean_abs_X: 7.7231 - val_loss: 10.9924 - val_tau: -10.2602 - val_mean_X: -7.6903 - val_mean_PnL: 0.1256 - val_mean_Cost: 0.1491 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8160 - val_var_emp: -9.9348 - val_mean_abs_X: 7.6903 - lr: 6.2500e-05\n",
      "Epoch 86/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0349 - tau: -10.2598 - mean_X: -7.7232 - mean_PnL: 0.1357 - mean_Cost: 0.1499 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9264 - var_emp: -10.0822 - mean_abs_X: 7.7232\n",
      "Epoch 86: val_cvar_emp did not improve from -10.81598\n",
      "\n",
      "Epoch 86: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 86: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 401ms/step - loss: 11.0349 - tau: -10.2598 - mean_X: -7.7232 - mean_PnL: 0.1357 - mean_Cost: 0.1499 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9264 - var_emp: -10.0822 - mean_abs_X: 7.7232 - val_loss: 10.9849 - val_tau: -10.2593 - val_mean_X: -7.6914 - val_mean_PnL: 0.1245 - val_mean_Cost: 0.1491 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8185 - val_var_emp: -9.9512 - val_mean_abs_X: 7.6914 - lr: 6.2500e-05\n",
      "Epoch 87/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0354 - tau: -10.2589 - mean_X: -7.7241 - mean_PnL: 0.1353 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9187 - var_emp: -10.0496 - mean_abs_X: 7.7241\n",
      "Epoch 87: val_cvar_emp did not improve from -10.81598\n",
      "\n",
      "Epoch 87: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 87: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 11.0354 - tau: -10.2589 - mean_X: -7.7241 - mean_PnL: 0.1353 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9187 - var_emp: -10.0496 - mean_abs_X: 7.7241 - val_loss: 11.0544 - val_tau: -10.2584 - val_mean_X: -7.6903 - val_mean_PnL: 0.1250 - val_mean_Cost: 0.1485 - val_turnover_mean: 0.0118 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8830 - val_var_emp: -9.9515 - val_mean_abs_X: 7.6903 - lr: 6.2500e-05\n",
      "Epoch 88/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0889 - tau: -10.2580 - mean_X: -7.7256 - mean_PnL: 0.1335 - mean_Cost: 0.1501 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9759 - var_emp: -10.0719 - mean_abs_X: 7.7256\n",
      "Epoch 88: val_cvar_emp did not improve from -10.81598\n",
      "\n",
      "Epoch 88: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 88: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 406ms/step - loss: 11.0889 - tau: -10.2580 - mean_X: -7.7256 - mean_PnL: 0.1335 - mean_Cost: 0.1501 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9759 - var_emp: -10.0719 - mean_abs_X: 7.7256 - val_loss: 11.0015 - val_tau: -10.2576 - val_mean_X: -7.6889 - val_mean_PnL: 0.1263 - val_mean_Cost: 0.1485 - val_turnover_mean: 0.0118 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8284 - val_var_emp: -9.9468 - val_mean_abs_X: 7.6889 - lr: 6.2500e-05\n",
      "Epoch 89/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0589 - tau: -10.2572 - mean_X: -7.7209 - mean_PnL: 0.1386 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9557 - var_emp: -10.0889 - mean_abs_X: 7.7209\n",
      "Epoch 89: val_cvar_emp improved from -10.81598 to -10.81100, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 89: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 89: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 11.0589 - tau: -10.2572 - mean_X: -7.7209 - mean_PnL: 0.1386 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9557 - var_emp: -10.0889 - mean_abs_X: 7.7209 - val_loss: 10.9843 - val_tau: -10.2569 - val_mean_X: -7.6915 - val_mean_PnL: 0.1251 - val_mean_Cost: 0.1499 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8110 - val_var_emp: -9.9379 - val_mean_abs_X: 7.6915 - lr: 6.2500e-05\n",
      "Epoch 90/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0415 - tau: -10.2565 - mean_X: -7.7233 - mean_PnL: 0.1353 - mean_Cost: 0.1497 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9300 - var_emp: -10.0614 - mean_abs_X: 7.7233\n",
      "Epoch 90: val_cvar_emp did not improve from -10.81100\n",
      "\n",
      "Epoch 90: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 90: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 408ms/step - loss: 11.0415 - tau: -10.2565 - mean_X: -7.7233 - mean_PnL: 0.1353 - mean_Cost: 0.1497 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9300 - var_emp: -10.0614 - mean_abs_X: 7.7233 - val_loss: 10.9840 - val_tau: -10.2560 - val_mean_X: -7.6894 - val_mean_PnL: 0.1276 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8400 - val_var_emp: -9.9890 - val_mean_abs_X: 7.6894 - lr: 6.2500e-05\n",
      "Epoch 91/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0319 - tau: -10.2556 - mean_X: -7.7252 - mean_PnL: 0.1348 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9214 - var_emp: -10.0536 - mean_abs_X: 7.7252\n",
      "Epoch 91: val_cvar_emp improved from -10.81100 to -10.80565, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 91: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 91: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 405ms/step - loss: 11.0319 - tau: -10.2556 - mean_X: -7.7252 - mean_PnL: 0.1348 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9214 - var_emp: -10.0536 - mean_abs_X: 7.7252 - val_loss: 10.9875 - val_tau: -10.2551 - val_mean_X: -7.6912 - val_mean_PnL: 0.1258 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8057 - val_var_emp: -9.9051 - val_mean_abs_X: 7.6912 - lr: 6.2500e-05\n",
      "Epoch 92/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0292 - tau: -10.2547 - mean_X: -7.7235 - mean_PnL: 0.1365 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9077 - var_emp: -10.0263 - mean_abs_X: 7.7235\n",
      "Epoch 92: val_cvar_emp did not improve from -10.80565\n",
      "\n",
      "Epoch 92: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 92: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 11.0292 - tau: -10.2547 - mean_X: -7.7235 - mean_PnL: 0.1365 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9077 - var_emp: -10.0263 - mean_abs_X: 7.7235 - val_loss: 10.9771 - val_tau: -10.2542 - val_mean_X: -7.6909 - val_mean_PnL: 0.1260 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8197 - val_var_emp: -9.9722 - val_mean_abs_X: 7.6909 - lr: 6.2500e-05\n",
      "Epoch 93/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0282 - tau: -10.2537 - mean_X: -7.7232 - mean_PnL: 0.1365 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9099 - var_emp: -10.0410 - mean_abs_X: 7.7232\n",
      "Epoch 93: val_cvar_emp did not improve from -10.80565\n",
      "\n",
      "Epoch 93: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 93: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 11.0282 - tau: -10.2537 - mean_X: -7.7232 - mean_PnL: 0.1365 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9099 - var_emp: -10.0410 - mean_abs_X: 7.7232 - val_loss: 10.9774 - val_tau: -10.2532 - val_mean_X: -7.6905 - val_mean_PnL: 0.1275 - val_mean_Cost: 0.1513 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8084 - val_var_emp: -9.9455 - val_mean_abs_X: 7.6905 - lr: 6.2500e-05\n",
      "Epoch 94/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0277 - tau: -10.2528 - mean_X: -7.7241 - mean_PnL: 0.1370 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9211 - var_emp: -10.0652 - mean_abs_X: 7.7241\n",
      "Epoch 94: val_cvar_emp improved from -10.80565 to -10.79346, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 94: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 94: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 11.0277 - tau: -10.2528 - mean_X: -7.7241 - mean_PnL: 0.1370 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9211 - var_emp: -10.0652 - mean_abs_X: 7.7241 - val_loss: 10.9804 - val_tau: -10.2523 - val_mean_X: -7.6904 - val_mean_PnL: 0.1281 - val_mean_Cost: 0.1518 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7935 - val_var_emp: -9.8909 - val_mean_abs_X: 7.6904 - lr: 6.2500e-05\n",
      "Epoch 95/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0212 - tau: -10.2518 - mean_X: -7.7219 - mean_PnL: 0.1395 - mean_Cost: 0.1525 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8976 - var_emp: -10.0207 - mean_abs_X: 7.7219\n",
      "Epoch 95: val_cvar_emp did not improve from -10.79346\n",
      "\n",
      "Epoch 95: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 95: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 11.0212 - tau: -10.2518 - mean_X: -7.7219 - mean_PnL: 0.1395 - mean_Cost: 0.1525 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8976 - var_emp: -10.0207 - mean_abs_X: 7.7219 - val_loss: 10.9716 - val_tau: -10.2512 - val_mean_X: -7.6909 - val_mean_PnL: 0.1261 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7991 - val_var_emp: -9.9213 - val_mean_abs_X: 7.6909 - lr: 6.2500e-05\n",
      "Epoch 96/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0291 - tau: -10.2508 - mean_X: -7.7244 - mean_PnL: 0.1349 - mean_Cost: 0.1504 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9136 - var_emp: -10.0278 - mean_abs_X: 7.7244\n",
      "Epoch 96: val_cvar_emp did not improve from -10.79346\n",
      "\n",
      "Epoch 96: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 96: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 11.0291 - tau: -10.2508 - mean_X: -7.7244 - mean_PnL: 0.1349 - mean_Cost: 0.1504 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9136 - var_emp: -10.0278 - mean_abs_X: 7.7244 - val_loss: 10.9693 - val_tau: -10.2503 - val_mean_X: -7.6900 - val_mean_PnL: 0.1270 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8110 - val_var_emp: -9.9542 - val_mean_abs_X: 7.6900 - lr: 6.2500e-05\n",
      "Epoch 97/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0248 - tau: -10.2499 - mean_X: -7.7283 - mean_PnL: 0.1329 - mean_Cost: 0.1523 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9121 - var_emp: -10.0221 - mean_abs_X: 7.7283\n",
      "Epoch 97: val_cvar_emp did not improve from -10.79346\n",
      "\n",
      "Epoch 97: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 97: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 431ms/step - loss: 11.0248 - tau: -10.2499 - mean_X: -7.7283 - mean_PnL: 0.1329 - mean_Cost: 0.1523 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9121 - var_emp: -10.0221 - mean_abs_X: 7.7283 - val_loss: 10.9829 - val_tau: -10.2494 - val_mean_X: -7.6897 - val_mean_PnL: 0.1270 - val_mean_Cost: 0.1500 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8046 - val_var_emp: -9.9105 - val_mean_abs_X: 7.6897 - lr: 6.2500e-05\n",
      "Epoch 98/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0255 - tau: -10.2489 - mean_X: -7.7209 - mean_PnL: 0.1377 - mean_Cost: 0.1496 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9119 - var_emp: -10.0333 - mean_abs_X: 7.7209\n",
      "Epoch 98: val_cvar_emp did not improve from -10.79346\n",
      "\n",
      "Epoch 98: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 98: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 11.0255 - tau: -10.2489 - mean_X: -7.7209 - mean_PnL: 0.1377 - mean_Cost: 0.1496 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9119 - var_emp: -10.0333 - mean_abs_X: 7.7209 - val_loss: 10.9836 - val_tau: -10.2483 - val_mean_X: -7.6919 - val_mean_PnL: 0.1233 - val_mean_Cost: 0.1484 - val_turnover_mean: 0.0118 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8097 - val_var_emp: -9.9279 - val_mean_abs_X: 7.6919 - lr: 6.2500e-05\n",
      "Epoch 99/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0216 - tau: -10.2479 - mean_X: -7.7252 - mean_PnL: 0.1349 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9136 - var_emp: -10.0620 - mean_abs_X: 7.7252\n",
      "Epoch 99: val_cvar_emp did not improve from -10.79346\n",
      "\n",
      "Epoch 99: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 99: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 427ms/step - loss: 11.0216 - tau: -10.2479 - mean_X: -7.7252 - mean_PnL: 0.1349 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9136 - var_emp: -10.0620 - mean_abs_X: 7.7252 - val_loss: 10.9832 - val_tau: -10.2474 - val_mean_X: -7.6894 - val_mean_PnL: 0.1268 - val_mean_Cost: 0.1494 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8495 - val_var_emp: -10.0307 - val_mean_abs_X: 7.6894 - lr: 6.2500e-05\n",
      "Epoch 100/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0152 - tau: -10.2470 - mean_X: -7.7215 - mean_PnL: 0.1375 - mean_Cost: 0.1500 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9034 - var_emp: -10.0518 - mean_abs_X: 7.7215\n",
      "Epoch 100: val_cvar_emp did not improve from -10.79346\n",
      "\n",
      "Epoch 100: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 100: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 419ms/step - loss: 11.0152 - tau: -10.2470 - mean_X: -7.7215 - mean_PnL: 0.1375 - mean_Cost: 0.1500 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9034 - var_emp: -10.0518 - mean_abs_X: 7.7215 - val_loss: 10.9716 - val_tau: -10.2465 - val_mean_X: -7.6900 - val_mean_PnL: 0.1273 - val_mean_Cost: 0.1505 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8245 - val_var_emp: -9.9931 - val_mean_abs_X: 7.6900 - lr: 6.2500e-05\n",
      "Epoch 101/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0139 - tau: -10.2461 - mean_X: -7.7267 - mean_PnL: 0.1336 - mean_Cost: 0.1514 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8937 - var_emp: -9.9973 - mean_abs_X: 7.7267 \n",
      "Epoch 101: val_cvar_emp did not improve from -10.79346\n",
      "\n",
      "Epoch 101: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 101: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 427ms/step - loss: 11.0139 - tau: -10.2461 - mean_X: -7.7267 - mean_PnL: 0.1336 - mean_Cost: 0.1514 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8937 - var_emp: -9.9973 - mean_abs_X: 7.7267 - val_loss: 10.9686 - val_tau: -10.2456 - val_mean_X: -7.6894 - val_mean_PnL: 0.1290 - val_mean_Cost: 0.1516 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8144 - val_var_emp: -9.9667 - val_mean_abs_X: 7.6894 - lr: 6.2500e-05\n",
      "Epoch 102/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0113 - tau: -10.2451 - mean_X: -7.7262 - mean_PnL: 0.1353 - mean_Cost: 0.1526 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.8960 - var_emp: -10.0356 - mean_abs_X: 7.7262\n",
      "Epoch 102: val_cvar_emp improved from -10.79346 to -10.79020, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 102: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 102: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 11.0113 - tau: -10.2451 - mean_X: -7.7262 - mean_PnL: 0.1353 - mean_Cost: 0.1526 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.8960 - var_emp: -10.0356 - mean_abs_X: 7.7262 - val_loss: 10.9660 - val_tau: -10.2445 - val_mean_X: -7.6925 - val_mean_PnL: 0.1256 - val_mean_Cost: 0.1513 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7902 - val_var_emp: -9.9048 - val_mean_abs_X: 7.6925 - lr: 6.2500e-05\n",
      "Epoch 103/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0095 - tau: -10.2440 - mean_X: -7.7244 - mean_PnL: 0.1358 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8926 - var_emp: -10.0381 - mean_abs_X: 7.7244\n",
      "Epoch 103: val_cvar_emp did not improve from -10.79020\n",
      "\n",
      "Epoch 103: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 103: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 11.0095 - tau: -10.2440 - mean_X: -7.7244 - mean_PnL: 0.1358 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8926 - var_emp: -10.0381 - mean_abs_X: 7.7244 - val_loss: 10.9890 - val_tau: -10.2434 - val_mean_X: -7.6927 - val_mean_PnL: 0.1239 - val_mean_Cost: 0.1498 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8083 - val_var_emp: -9.9079 - val_mean_abs_X: 7.6927 - lr: 6.2500e-05\n",
      "Epoch 104/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0296 - tau: -10.2430 - mean_X: -7.7202 - mean_PnL: 0.1393 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9166 - var_emp: -10.0379 - mean_abs_X: 7.7202\n",
      "Epoch 104: val_cvar_emp did not improve from -10.79020\n",
      "\n",
      "Epoch 104: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 104: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 11.0296 - tau: -10.2430 - mean_X: -7.7202 - mean_PnL: 0.1393 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.9166 - var_emp: -10.0379 - mean_abs_X: 7.7202 - val_loss: 10.9620 - val_tau: -10.2425 - val_mean_X: -7.6920 - val_mean_PnL: 0.1241 - val_mean_Cost: 0.1494 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8097 - val_var_emp: -9.9643 - val_mean_abs_X: 7.6920 - lr: 6.2500e-05\n",
      "Epoch 105/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0115 - tau: -10.2421 - mean_X: -7.7244 - mean_PnL: 0.1341 - mean_Cost: 0.1496 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9066 - var_emp: -10.0685 - mean_abs_X: 7.7244\n",
      "Epoch 105: val_cvar_emp did not improve from -10.79020\n",
      "\n",
      "Epoch 105: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 105: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 401ms/step - loss: 11.0115 - tau: -10.2421 - mean_X: -7.7244 - mean_PnL: 0.1341 - mean_Cost: 0.1496 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.9066 - var_emp: -10.0685 - mean_abs_X: 7.7244 - val_loss: 10.9732 - val_tau: -10.2416 - val_mean_X: -7.6912 - val_mean_PnL: 0.1250 - val_mean_Cost: 0.1495 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8033 - val_var_emp: -9.9301 - val_mean_abs_X: 7.6912 - lr: 6.2500e-05\n",
      "Epoch 106/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9994 - tau: -10.2411 - mean_X: -7.7238 - mean_PnL: 0.1364 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8886 - var_emp: -10.0564 - mean_abs_X: 7.7238\n",
      "Epoch 106: val_cvar_emp did not improve from -10.79020\n",
      "\n",
      "Epoch 106: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 106: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 395ms/step - loss: 10.9994 - tau: -10.2411 - mean_X: -7.7238 - mean_PnL: 0.1364 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8886 - var_emp: -10.0564 - mean_abs_X: 7.7238 - val_loss: 10.9724 - val_tau: -10.2406 - val_mean_X: -7.6931 - val_mean_PnL: 0.1237 - val_mean_Cost: 0.1501 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7946 - val_var_emp: -9.9060 - val_mean_abs_X: 7.6931 - lr: 6.2500e-05\n",
      "Epoch 107/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0173 - tau: -10.2402 - mean_X: -7.7258 - mean_PnL: 0.1342 - mean_Cost: 0.1511 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9020 - var_emp: -10.0262 - mean_abs_X: 7.7258\n",
      "Epoch 107: val_cvar_emp improved from -10.79020 to -10.78821, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 107: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 107: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 11.0173 - tau: -10.2402 - mean_X: -7.7258 - mean_PnL: 0.1342 - mean_Cost: 0.1511 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9020 - var_emp: -10.0262 - mean_abs_X: 7.7258 - val_loss: 10.9617 - val_tau: -10.2397 - val_mean_X: -7.6914 - val_mean_PnL: 0.1268 - val_mean_Cost: 0.1515 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7882 - val_var_emp: -9.9005 - val_mean_abs_X: 7.6914 - lr: 6.2500e-05\n",
      "Epoch 108/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9956 - tau: -10.2392 - mean_X: -7.7265 - mean_PnL: 0.1346 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8793 - var_emp: -10.0158 - mean_abs_X: 7.7265\n",
      "Epoch 108: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 108: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 108: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 10.9956 - tau: -10.2392 - mean_X: -7.7265 - mean_PnL: 0.1346 - mean_Cost: 0.1521 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8793 - var_emp: -10.0158 - mean_abs_X: 7.7265 - val_loss: 10.9750 - val_tau: -10.2386 - val_mean_X: -7.6922 - val_mean_PnL: 0.1250 - val_mean_Cost: 0.1504 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8413 - val_var_emp: -10.0188 - val_mean_abs_X: 7.6922 - lr: 6.2500e-05\n",
      "Epoch 109/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0020 - tau: -10.2382 - mean_X: -7.7216 - mean_PnL: 0.1382 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8891 - var_emp: -10.0288 - mean_abs_X: 7.7216\n",
      "Epoch 109: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 109: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 109: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 386ms/step - loss: 11.0020 - tau: -10.2382 - mean_X: -7.7216 - mean_PnL: 0.1382 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8891 - var_emp: -10.0288 - mean_abs_X: 7.7216 - val_loss: 10.9938 - val_tau: -10.2376 - val_mean_X: -7.6924 - val_mean_PnL: 0.1265 - val_mean_Cost: 0.1522 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8610 - val_var_emp: -10.0172 - val_mean_abs_X: 7.6924 - lr: 6.2500e-05\n",
      "Epoch 110/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0035 - tau: -10.2371 - mean_X: -7.7255 - mean_PnL: 0.1353 - mean_Cost: 0.1519 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8888 - var_emp: -10.0179 - mean_abs_X: 7.7255\n",
      "Epoch 110: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 110: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 110: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 383ms/step - loss: 11.0035 - tau: -10.2371 - mean_X: -7.7255 - mean_PnL: 0.1353 - mean_Cost: 0.1519 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8888 - var_emp: -10.0179 - mean_abs_X: 7.7255 - val_loss: 10.9715 - val_tau: -10.2365 - val_mean_X: -7.6912 - val_mean_PnL: 0.1243 - val_mean_Cost: 0.1488 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8079 - val_var_emp: -9.9400 - val_mean_abs_X: 7.6912 - lr: 6.2500e-05\n",
      "Epoch 111/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0004 - tau: -10.2360 - mean_X: -7.7229 - mean_PnL: 0.1355 - mean_Cost: 0.1495 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.8938 - var_emp: -10.0571 - mean_abs_X: 7.7229\n",
      "Epoch 111: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 111: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 111: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 11.0004 - tau: -10.2360 - mean_X: -7.7229 - mean_PnL: 0.1355 - mean_Cost: 0.1495 - turnover_mean: 0.0119 - bound_frac: 0.0000e+00 - cvar_emp: -10.8938 - var_emp: -10.0571 - mean_abs_X: 7.7229 - val_loss: 10.9780 - val_tau: -10.2356 - val_mean_X: -7.6922 - val_mean_PnL: 0.1246 - val_mean_Cost: 0.1500 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8007 - val_var_emp: -9.9116 - val_mean_abs_X: 7.6922 - lr: 6.2500e-05\n",
      "Epoch 112/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0046 - tau: -10.2351 - mean_X: -7.7254 - mean_PnL: 0.1346 - mean_Cost: 0.1511 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8916 - var_emp: -10.0230 - mean_abs_X: 7.7254\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 112: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 112: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 112: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 11.0046 - tau: -10.2351 - mean_X: -7.7254 - mean_PnL: 0.1346 - mean_Cost: 0.1511 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8916 - var_emp: -10.0230 - mean_abs_X: 7.7254 - val_loss: 11.0119 - val_tau: -10.2345 - val_mean_X: -7.6926 - val_mean_PnL: 0.1254 - val_mean_Cost: 0.1513 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8929 - val_var_emp: -10.0906 - val_mean_abs_X: 7.6926 - lr: 6.2500e-05\n",
      "Epoch 113/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0349 - tau: -10.2343 - mean_X: -7.7277 - mean_PnL: 0.1330 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9267 - var_emp: -10.0432 - mean_abs_X: 7.7277\n",
      "Epoch 113: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 113: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 113: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 415ms/step - loss: 11.0349 - tau: -10.2343 - mean_X: -7.7277 - mean_PnL: 0.1330 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.9267 - var_emp: -10.0432 - mean_abs_X: 7.7277 - val_loss: 10.9744 - val_tau: -10.2341 - val_mean_X: -7.6924 - val_mean_PnL: 0.1263 - val_mean_Cost: 0.1519 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8415 - val_var_emp: -10.0142 - val_mean_abs_X: 7.6924 - lr: 3.1250e-05\n",
      "Epoch 114/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0230 - tau: -10.2339 - mean_X: -7.7276 - mean_PnL: 0.1339 - mean_Cost: 0.1526 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9107 - var_emp: -10.0680 - mean_abs_X: 7.7276\n",
      "Epoch 114: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 114: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 114: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 401ms/step - loss: 11.0230 - tau: -10.2339 - mean_X: -7.7276 - mean_PnL: 0.1339 - mean_Cost: 0.1526 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.9107 - var_emp: -10.0680 - mean_abs_X: 7.7276 - val_loss: 10.9514 - val_tau: -10.2337 - val_mean_X: -7.6911 - val_mean_PnL: 0.1279 - val_mean_Cost: 0.1523 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7933 - val_var_emp: -9.9404 - val_mean_abs_X: 7.6911 - lr: 3.1250e-05\n",
      "Epoch 115/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9953 - tau: -10.2335 - mean_X: -7.7257 - mean_PnL: 0.1363 - mean_Cost: 0.1531 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.8728 - var_emp: -10.0092 - mean_abs_X: 7.7257\n",
      "Epoch 115: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 115: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 115: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 412ms/step - loss: 10.9953 - tau: -10.2335 - mean_X: -7.7257 - mean_PnL: 0.1363 - mean_Cost: 0.1531 - turnover_mean: 0.0122 - bound_frac: 0.0000e+00 - cvar_emp: -10.8728 - var_emp: -10.0092 - mean_abs_X: 7.7257 - val_loss: 10.9743 - val_tau: -10.2332 - val_mean_X: -7.6920 - val_mean_PnL: 0.1267 - val_mean_Cost: 0.1520 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8341 - val_var_emp: -9.9977 - val_mean_abs_X: 7.6920 - lr: 3.1250e-05\n",
      "Epoch 116/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9976 - tau: -10.2330 - mean_X: -7.7252 - mean_PnL: 0.1353 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8853 - var_emp: -10.0103 - mean_abs_X: 7.7252\n",
      "Epoch 116: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 116: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 116: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 400ms/step - loss: 10.9976 - tau: -10.2330 - mean_X: -7.7252 - mean_PnL: 0.1353 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8853 - var_emp: -10.0103 - mean_abs_X: 7.7252 - val_loss: 10.9881 - val_tau: -10.2328 - val_mean_X: -7.6926 - val_mean_PnL: 0.1253 - val_mean_Cost: 0.1511 - val_turnover_mean: 0.0121 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8584 - val_var_emp: -10.0182 - val_mean_abs_X: 7.6926 - lr: 3.1250e-05\n",
      "Epoch 117/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9878 - tau: -10.2325 - mean_X: -7.7231 - mean_PnL: 0.1371 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8635 - var_emp: -10.0040 - mean_abs_X: 7.7231\n",
      "Epoch 117: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 117: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 117: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 388ms/step - loss: 10.9878 - tau: -10.2325 - mean_X: -7.7231 - mean_PnL: 0.1371 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8635 - var_emp: -10.0040 - mean_abs_X: 7.7231 - val_loss: 10.9580 - val_tau: -10.2323 - val_mean_X: -7.6904 - val_mean_PnL: 0.1272 - val_mean_Cost: 0.1509 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8134 - val_var_emp: -9.9797 - val_mean_abs_X: 7.6904 - lr: 3.1250e-05\n",
      "Epoch 118/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9955 - tau: -10.2320 - mean_X: -7.7218 - mean_PnL: 0.1380 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8862 - var_emp: -10.0546 - mean_abs_X: 7.7218\n",
      "Epoch 118: val_cvar_emp did not improve from -10.78821\n",
      "\n",
      "Epoch 118: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 118: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 389ms/step - loss: 10.9955 - tau: -10.2320 - mean_X: -7.7218 - mean_PnL: 0.1380 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8862 - var_emp: -10.0546 - mean_abs_X: 7.7218 - val_loss: 10.9645 - val_tau: -10.2317 - val_mean_X: -7.6909 - val_mean_PnL: 0.1262 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8261 - val_var_emp: -10.0009 - val_mean_abs_X: 7.6909 - lr: 3.1250e-05\n",
      "Epoch 119/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9863 - tau: -10.2315 - mean_X: -7.7236 - mean_PnL: 0.1362 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8705 - var_emp: -10.0360 - mean_abs_X: 7.7236\n",
      "Epoch 119: val_cvar_emp improved from -10.78821 to -10.77513, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 119: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 119: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 10.9863 - tau: -10.2315 - mean_X: -7.7236 - mean_PnL: 0.1362 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8705 - var_emp: -10.0360 - mean_abs_X: 7.7236 - val_loss: 10.9439 - val_tau: -10.2312 - val_mean_X: -7.6902 - val_mean_PnL: 0.1268 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7751 - val_var_emp: -9.9164 - val_mean_abs_X: 7.6902 - lr: 3.1250e-05\n",
      "Epoch 120/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9902 - tau: -10.2310 - mean_X: -7.7252 - mean_PnL: 0.1350 - mean_Cost: 0.1512 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8806 - var_emp: -10.0326 - mean_abs_X: 7.7252\n",
      "Epoch 120: val_cvar_emp did not improve from -10.77513\n",
      "\n",
      "Epoch 120: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 120: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 433ms/step - loss: 10.9902 - tau: -10.2310 - mean_X: -7.7252 - mean_PnL: 0.1350 - mean_Cost: 0.1512 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8806 - var_emp: -10.0326 - mean_abs_X: 7.7252 - val_loss: 10.9641 - val_tau: -10.2307 - val_mean_X: -7.6897 - val_mean_PnL: 0.1265 - val_mean_Cost: 0.1494 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7920 - val_var_emp: -9.8982 - val_mean_abs_X: 7.6897 - lr: 3.1250e-05\n",
      "Epoch 121/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 11.0013 - tau: -10.2305 - mean_X: -7.7246 - mean_PnL: 0.1344 - mean_Cost: 0.1501 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8879 - var_emp: -10.0228 - mean_abs_X: 7.7246\n",
      "Epoch 121: val_cvar_emp did not improve from -10.77513\n",
      "\n",
      "Epoch 121: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 121: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 435ms/step - loss: 11.0013 - tau: -10.2305 - mean_X: -7.7246 - mean_PnL: 0.1344 - mean_Cost: 0.1501 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8879 - var_emp: -10.0228 - mean_abs_X: 7.7246 - val_loss: 10.9695 - val_tau: -10.2302 - val_mean_X: -7.6913 - val_mean_PnL: 0.1245 - val_mean_Cost: 0.1491 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8033 - val_var_emp: -9.9365 - val_mean_abs_X: 7.6913 - lr: 3.1250e-05\n",
      "Epoch 122/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9804 - tau: -10.2300 - mean_X: -7.7241 - mean_PnL: 0.1357 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8717 - var_emp: -10.0402 - mean_abs_X: 7.7241\n",
      "Epoch 122: val_cvar_emp improved from -10.77513 to -10.77382, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 122: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 122: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 432ms/step - loss: 10.9804 - tau: -10.2300 - mean_X: -7.7241 - mean_PnL: 0.1357 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8717 - var_emp: -10.0402 - mean_abs_X: 7.7241 - val_loss: 10.9444 - val_tau: -10.2297 - val_mean_X: -7.6914 - val_mean_PnL: 0.1265 - val_mean_Cost: 0.1511 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7738 - val_var_emp: -9.8971 - val_mean_abs_X: 7.6914 - lr: 3.1250e-05\n",
      "Epoch 123/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9840 - tau: -10.2294 - mean_X: -7.7248 - mean_PnL: 0.1360 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8616 - var_emp: -9.9870 - mean_abs_X: 7.7248\n",
      "Epoch 123: val_cvar_emp did not improve from -10.77382\n",
      "\n",
      "Epoch 123: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 123: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 439ms/step - loss: 10.9840 - tau: -10.2294 - mean_X: -7.7248 - mean_PnL: 0.1360 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8616 - var_emp: -9.9870 - mean_abs_X: 7.7248 - val_loss: 10.9412 - val_tau: -10.2292 - val_mean_X: -7.6908 - val_mean_PnL: 0.1264 - val_mean_Cost: 0.1505 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7765 - val_var_emp: -9.9238 - val_mean_abs_X: 7.6908 - lr: 3.1250e-05\n",
      "Epoch 124/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9859 - tau: -10.2289 - mean_X: -7.7246 - mean_PnL: 0.1353 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8737 - var_emp: -10.0262 - mean_abs_X: 7.7246\n",
      "Epoch 124: val_cvar_emp did not improve from -10.77382\n",
      "\n",
      "Epoch 124: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 124: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 378ms/step - loss: 10.9859 - tau: -10.2289 - mean_X: -7.7246 - mean_PnL: 0.1353 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8737 - var_emp: -10.0262 - mean_abs_X: 7.7246 - val_loss: 10.9631 - val_tau: -10.2286 - val_mean_X: -7.6903 - val_mean_PnL: 0.1266 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7862 - val_var_emp: -9.8881 - val_mean_abs_X: 7.6903 - lr: 3.1250e-05\n",
      "Epoch 125/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9903 - tau: -10.2284 - mean_X: -7.7249 - mean_PnL: 0.1349 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8836 - var_emp: -10.0219 - mean_abs_X: 7.7249\n",
      "Epoch 125: val_cvar_emp improved from -10.77382 to -10.77302, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 125: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 125: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 437ms/step - loss: 10.9903 - tau: -10.2284 - mean_X: -7.7249 - mean_PnL: 0.1349 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8836 - var_emp: -10.0219 - mean_abs_X: 7.7249 - val_loss: 10.9422 - val_tau: -10.2281 - val_mean_X: -7.6904 - val_mean_PnL: 0.1265 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7730 - val_var_emp: -9.9076 - val_mean_abs_X: 7.6904 - lr: 3.1250e-05\n",
      "Epoch 126/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9776 - tau: -10.2279 - mean_X: -7.7240 - mean_PnL: 0.1367 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8661 - var_emp: -10.0136 - mean_abs_X: 7.7240\n",
      "Epoch 126: val_cvar_emp did not improve from -10.77302\n",
      "\n",
      "Epoch 126: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 126: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 414ms/step - loss: 10.9776 - tau: -10.2279 - mean_X: -7.7240 - mean_PnL: 0.1367 - mean_Cost: 0.1518 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8661 - var_emp: -10.0136 - mean_abs_X: 7.7240 - val_loss: 10.9434 - val_tau: -10.2276 - val_mean_X: -7.6915 - val_mean_PnL: 0.1264 - val_mean_Cost: 0.1512 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7744 - val_var_emp: -9.8966 - val_mean_abs_X: 7.6915 - lr: 3.1250e-05\n",
      "Epoch 127/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9856 - tau: -10.2274 - mean_X: -7.7246 - mean_PnL: 0.1361 - mean_Cost: 0.1517 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8659 - var_emp: -10.0016 - mean_abs_X: 7.7246\n",
      "Epoch 127: val_cvar_emp did not improve from -10.77302\n",
      "\n",
      "Epoch 127: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 127: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 447ms/step - loss: 10.9856 - tau: -10.2274 - mean_X: -7.7246 - mean_PnL: 0.1361 - mean_Cost: 0.1517 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8659 - var_emp: -10.0016 - mean_abs_X: 7.7246 - val_loss: 10.9412 - val_tau: -10.2271 - val_mean_X: -7.6887 - val_mean_PnL: 0.1284 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7852 - val_var_emp: -9.9445 - val_mean_abs_X: 7.6887 - lr: 3.1250e-05\n",
      "Epoch 128/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9782 - tau: -10.2268 - mean_X: -7.7252 - mean_PnL: 0.1342 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8602 - var_emp: -10.0001 - mean_abs_X: 7.7252\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 128: val_cvar_emp did not improve from -10.77302\n",
      "\n",
      "Epoch 128: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 128: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 438ms/step - loss: 10.9782 - tau: -10.2268 - mean_X: -7.7252 - mean_PnL: 0.1342 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8602 - var_emp: -10.0001 - mean_abs_X: 7.7252 - val_loss: 10.9466 - val_tau: -10.2265 - val_mean_X: -7.6904 - val_mean_PnL: 0.1255 - val_mean_Cost: 0.1492 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7798 - val_var_emp: -9.9157 - val_mean_abs_X: 7.6904 - lr: 3.1250e-05\n",
      "Epoch 129/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9728 - tau: -10.2264 - mean_X: -7.7224 - mean_PnL: 0.1369 - mean_Cost: 0.1504 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8588 - var_emp: -10.0183 - mean_abs_X: 7.7224\n",
      "Epoch 129: val_cvar_emp did not improve from -10.77302\n",
      "\n",
      "Epoch 129: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 129: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 444ms/step - loss: 10.9728 - tau: -10.2264 - mean_X: -7.7224 - mean_PnL: 0.1369 - mean_Cost: 0.1504 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8588 - var_emp: -10.0183 - mean_abs_X: 7.7224 - val_loss: 10.9388 - val_tau: -10.2262 - val_mean_X: -7.6910 - val_mean_PnL: 0.1259 - val_mean_Cost: 0.1501 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7806 - val_var_emp: -9.9332 - val_mean_abs_X: 7.6910 - lr: 1.5625e-05\n",
      "Epoch 130/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9766 - tau: -10.2261 - mean_X: -7.7246 - mean_PnL: 0.1355 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8623 - var_emp: -10.0168 - mean_abs_X: 7.7246\n",
      "Epoch 130: val_cvar_emp did not improve from -10.77302\n",
      "\n",
      "Epoch 130: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 130: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 450ms/step - loss: 10.9766 - tau: -10.2261 - mean_X: -7.7246 - mean_PnL: 0.1355 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8623 - var_emp: -10.0168 - mean_abs_X: 7.7246 - val_loss: 10.9393 - val_tau: -10.2260 - val_mean_X: -7.6899 - val_mean_PnL: 0.1277 - val_mean_Cost: 0.1508 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7844 - val_var_emp: -9.9343 - val_mean_abs_X: 7.6899 - lr: 1.5625e-05\n",
      "Epoch 131/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9713 - tau: -10.2258 - mean_X: -7.7251 - mean_PnL: 0.1356 - mean_Cost: 0.1517 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8532 - var_emp: -9.9914 - mean_abs_X: 7.7251\n",
      "Epoch 131: val_cvar_emp improved from -10.77302 to -10.77151, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 131: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 131: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 430ms/step - loss: 10.9713 - tau: -10.2258 - mean_X: -7.7251 - mean_PnL: 0.1356 - mean_Cost: 0.1517 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8532 - var_emp: -9.9914 - mean_abs_X: 7.7251 - val_loss: 10.9385 - val_tau: -10.2257 - val_mean_X: -7.6898 - val_mean_PnL: 0.1280 - val_mean_Cost: 0.1511 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7715 - val_var_emp: -9.9014 - val_mean_abs_X: 7.6898 - lr: 1.5625e-05\n",
      "Epoch 132/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9804 - tau: -10.2256 - mean_X: -7.7244 - mean_PnL: 0.1359 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8660 - var_emp: -10.0277 - mean_abs_X: 7.7244\n",
      "Epoch 132: val_cvar_emp did not improve from -10.77151\n",
      "\n",
      "Epoch 132: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 132: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 426ms/step - loss: 10.9804 - tau: -10.2256 - mean_X: -7.7244 - mean_PnL: 0.1359 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8660 - var_emp: -10.0277 - mean_abs_X: 7.7244 - val_loss: 10.9503 - val_tau: -10.2254 - val_mean_X: -7.6900 - val_mean_PnL: 0.1264 - val_mean_Cost: 0.1497 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7785 - val_var_emp: -9.8992 - val_mean_abs_X: 7.6900 - lr: 1.5625e-05\n",
      "Epoch 133/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9713 - tau: -10.2253 - mean_X: -7.7235 - mean_PnL: 0.1363 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8569 - var_emp: -10.0150 - mean_abs_X: 7.7235\n",
      "Epoch 133: val_cvar_emp did not improve from -10.77151\n",
      "\n",
      "Epoch 133: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 133: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 10.9713 - tau: -10.2253 - mean_X: -7.7235 - mean_PnL: 0.1363 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8569 - var_emp: -10.0150 - mean_abs_X: 7.7235 - val_loss: 10.9374 - val_tau: -10.2251 - val_mean_X: -7.6905 - val_mean_PnL: 0.1263 - val_mean_Cost: 0.1501 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7729 - val_var_emp: -9.9182 - val_mean_abs_X: 7.6905 - lr: 1.5625e-05\n",
      "Epoch 134/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9715 - tau: -10.2250 - mean_X: -7.7225 - mean_PnL: 0.1373 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8558 - var_emp: -9.9920 - mean_abs_X: 7.7225\n",
      "Epoch 134: val_cvar_emp did not improve from -10.77151\n",
      "\n",
      "Epoch 134: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 134: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 437ms/step - loss: 10.9715 - tau: -10.2250 - mean_X: -7.7225 - mean_PnL: 0.1373 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8558 - var_emp: -9.9920 - mean_abs_X: 7.7225 - val_loss: 10.9388 - val_tau: -10.2249 - val_mean_X: -7.6908 - val_mean_PnL: 0.1263 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7810 - val_var_emp: -9.9301 - val_mean_abs_X: 7.6908 - lr: 1.5625e-05\n",
      "Epoch 135/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9712 - tau: -10.2247 - mean_X: -7.7233 - mean_PnL: 0.1364 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8584 - var_emp: -10.0039 - mean_abs_X: 7.7233\n",
      "Epoch 135: val_cvar_emp did not improve from -10.77151\n",
      "\n",
      "Epoch 135: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 135: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 436ms/step - loss: 10.9712 - tau: -10.2247 - mean_X: -7.7233 - mean_PnL: 0.1364 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8584 - var_emp: -10.0039 - mean_abs_X: 7.7233 - val_loss: 10.9367 - val_tau: -10.2246 - val_mean_X: -7.6908 - val_mean_PnL: 0.1259 - val_mean_Cost: 0.1500 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7807 - val_var_emp: -9.9444 - val_mean_abs_X: 7.6908 - lr: 1.5625e-05\n",
      "Epoch 136/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9681 - tau: -10.2245 - mean_X: -7.7229 - mean_PnL: 0.1366 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8536 - var_emp: -10.0122 - mean_abs_X: 7.7229\n",
      "Epoch 136: val_cvar_emp did not improve from -10.77151\n",
      "\n",
      "Epoch 136: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 136: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 444ms/step - loss: 10.9681 - tau: -10.2245 - mean_X: -7.7229 - mean_PnL: 0.1366 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8536 - var_emp: -10.0122 - mean_abs_X: 7.7229 - val_loss: 10.9362 - val_tau: -10.2243 - val_mean_X: -7.6900 - val_mean_PnL: 0.1265 - val_mean_Cost: 0.1498 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7871 - val_var_emp: -9.9615 - val_mean_abs_X: 7.6900 - lr: 1.5625e-05\n",
      "Epoch 137/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9715 - tau: -10.2242 - mean_X: -7.7248 - mean_PnL: 0.1346 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8566 - var_emp: -10.0068 - mean_abs_X: 7.7248\n",
      "Epoch 137: val_cvar_emp did not improve from -10.77151\n",
      "\n",
      "Epoch 137: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 137: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 448ms/step - loss: 10.9715 - tau: -10.2242 - mean_X: -7.7248 - mean_PnL: 0.1346 - mean_Cost: 0.1505 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8566 - var_emp: -10.0068 - mean_abs_X: 7.7248 - val_loss: 10.9359 - val_tau: -10.2241 - val_mean_X: -7.6898 - val_mean_PnL: 0.1269 - val_mean_Cost: 0.1499 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7865 - val_var_emp: -9.9595 - val_mean_abs_X: 7.6898 - lr: 1.5625e-05\n",
      "Epoch 138/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9679 - tau: -10.2239 - mean_X: -7.7243 - mean_PnL: 0.1353 - mean_Cost: 0.1507 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8541 - var_emp: -10.0085 - mean_abs_X: 7.7243\n",
      "Epoch 138: val_cvar_emp did not improve from -10.77151\n",
      "\n",
      "Epoch 138: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 138: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 448ms/step - loss: 10.9679 - tau: -10.2239 - mean_X: -7.7243 - mean_PnL: 0.1353 - mean_Cost: 0.1507 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8541 - var_emp: -10.0085 - mean_abs_X: 7.7243 - val_loss: 10.9330 - val_tau: -10.2238 - val_mean_X: -7.6900 - val_mean_PnL: 0.1268 - val_mean_Cost: 0.1501 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7756 - val_var_emp: -9.9402 - val_mean_abs_X: 7.6900 - lr: 1.5625e-05\n",
      "Epoch 139/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9689 - tau: -10.2237 - mean_X: -7.7232 - mean_PnL: 0.1369 - mean_Cost: 0.1512 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8549 - var_emp: -9.9997 - mean_abs_X: 7.7232 \n",
      "Epoch 139: val_cvar_emp improved from -10.77151 to -10.76401, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 139: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 139: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 444ms/step - loss: 10.9689 - tau: -10.2237 - mean_X: -7.7232 - mean_PnL: 0.1369 - mean_Cost: 0.1512 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8549 - var_emp: -9.9997 - mean_abs_X: 7.7232 - val_loss: 10.9396 - val_tau: -10.2235 - val_mean_X: -7.6898 - val_mean_PnL: 0.1271 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7640 - val_var_emp: -9.8940 - val_mean_abs_X: 7.6898 - lr: 1.5625e-05\n",
      "Epoch 140/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9672 - tau: -10.2234 - mean_X: -7.7227 - mean_PnL: 0.1371 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8510 - var_emp: -10.0039 - mean_abs_X: 7.7227\n",
      "Epoch 140: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 140: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 140: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 10.9672 - tau: -10.2234 - mean_X: -7.7227 - mean_PnL: 0.1371 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8510 - var_emp: -10.0039 - mean_abs_X: 7.7227 - val_loss: 10.9324 - val_tau: -10.2232 - val_mean_X: -7.6902 - val_mean_PnL: 0.1265 - val_mean_Cost: 0.1500 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7737 - val_var_emp: -9.9358 - val_mean_abs_X: 7.6902 - lr: 1.5625e-05\n",
      "Epoch 141/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9694 - tau: -10.2231 - mean_X: -7.7239 - mean_PnL: 0.1356 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8517 - var_emp: -10.0077 - mean_abs_X: 7.7239\n",
      "Epoch 141: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 141: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 141: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 10.9694 - tau: -10.2231 - mean_X: -7.7239 - mean_PnL: 0.1356 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8517 - var_emp: -10.0077 - mean_abs_X: 7.7239 - val_loss: 10.9322 - val_tau: -10.2229 - val_mean_X: -7.6896 - val_mean_PnL: 0.1272 - val_mean_Cost: 0.1500 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7731 - val_var_emp: -9.9342 - val_mean_abs_X: 7.6896 - lr: 1.5625e-05\n",
      "Epoch 142/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9679 - tau: -10.2228 - mean_X: -7.7243 - mean_PnL: 0.1356 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8532 - var_emp: -10.0111 - mean_abs_X: 7.7243\n",
      "Epoch 142: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 142: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 142: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 449ms/step - loss: 10.9679 - tau: -10.2228 - mean_X: -7.7243 - mean_PnL: 0.1356 - mean_Cost: 0.1510 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8532 - var_emp: -10.0111 - mean_abs_X: 7.7243 - val_loss: 10.9322 - val_tau: -10.2227 - val_mean_X: -7.6894 - val_mean_PnL: 0.1276 - val_mean_Cost: 0.1503 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7759 - val_var_emp: -9.9383 - val_mean_abs_X: 7.6894 - lr: 1.5625e-05\n",
      "Epoch 143/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9698 - tau: -10.2225 - mean_X: -7.7240 - mean_PnL: 0.1357 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8546 - var_emp: -10.0204 - mean_abs_X: 7.7240\n",
      "Epoch 143: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 143: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 143: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 431ms/step - loss: 10.9698 - tau: -10.2225 - mean_X: -7.7240 - mean_PnL: 0.1357 - mean_Cost: 0.1508 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8546 - var_emp: -10.0204 - mean_abs_X: 7.7240 - val_loss: 10.9341 - val_tau: -10.2224 - val_mean_X: -7.6901 - val_mean_PnL: 0.1266 - val_mean_Cost: 0.1500 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7646 - val_var_emp: -9.9065 - val_mean_abs_X: 7.6901 - lr: 1.5625e-05\n",
      "Epoch 144/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9659 - tau: -10.2223 - mean_X: -7.7245 - mean_PnL: 0.1357 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8396 - var_emp: -9.9955 - mean_abs_X: 7.7245\n",
      "Epoch 144: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 144: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 144: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 10.9659 - tau: -10.2223 - mean_X: -7.7245 - mean_PnL: 0.1357 - mean_Cost: 0.1513 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8396 - var_emp: -9.9955 - mean_abs_X: 7.7245 - val_loss: 10.9322 - val_tau: -10.2221 - val_mean_X: -7.6904 - val_mean_PnL: 0.1270 - val_mean_Cost: 0.1507 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7641 - val_var_emp: -9.9072 - val_mean_abs_X: 7.6904 - lr: 1.5625e-05\n",
      "Epoch 145/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9653 - tau: -10.2220 - mean_X: -7.7234 - mean_PnL: 0.1366 - mean_Cost: 0.1512 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8455 - var_emp: -9.9800 - mean_abs_X: 7.7234\n",
      "Epoch 145: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 145: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 145: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 403ms/step - loss: 10.9653 - tau: -10.2220 - mean_X: -7.7234 - mean_PnL: 0.1366 - mean_Cost: 0.1512 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8455 - var_emp: -9.9800 - mean_abs_X: 7.7234 - val_loss: 10.9310 - val_tau: -10.2218 - val_mean_X: -7.6903 - val_mean_PnL: 0.1266 - val_mean_Cost: 0.1502 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7705 - val_var_emp: -9.9335 - val_mean_abs_X: 7.6903 - lr: 1.5625e-05\n",
      "Epoch 146/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9650 - tau: -10.2217 - mean_X: -7.7231 - mean_PnL: 0.1364 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8526 - var_emp: -10.0109 - mean_abs_X: 7.7231\n",
      "Epoch 146: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 146: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 146: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 10.9650 - tau: -10.2217 - mean_X: -7.7231 - mean_PnL: 0.1364 - mean_Cost: 0.1506 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8526 - var_emp: -10.0109 - mean_abs_X: 7.7231 - val_loss: 10.9319 - val_tau: -10.2216 - val_mean_X: -7.6909 - val_mean_PnL: 0.1254 - val_mean_Cost: 0.1495 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7727 - val_var_emp: -9.9345 - val_mean_abs_X: 7.6909 - lr: 1.5625e-05\n",
      "Epoch 147/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9672 - tau: -10.2214 - mean_X: -7.7233 - mean_PnL: 0.1360 - mean_Cost: 0.1504 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8580 - var_emp: -10.0192 - mean_abs_X: 7.7233\n",
      "Epoch 147: val_cvar_emp did not improve from -10.76401\n",
      "\n",
      "Epoch 147: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 147: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 453ms/step - loss: 10.9672 - tau: -10.2214 - mean_X: -7.7233 - mean_PnL: 0.1360 - mean_Cost: 0.1504 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8580 - var_emp: -10.0192 - mean_abs_X: 7.7233 - val_loss: 10.9320 - val_tau: -10.2213 - val_mean_X: -7.6909 - val_mean_PnL: 0.1256 - val_mean_Cost: 0.1498 - val_turnover_mean: 0.0119 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7691 - val_var_emp: -9.9220 - val_mean_abs_X: 7.6909 - lr: 1.5625e-05\n",
      "Epoch 148/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9699 - tau: -10.2212 - mean_X: -7.7235 - mean_PnL: 0.1365 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8510 - var_emp: -9.9904 - mean_abs_X: 7.7235\n",
      "Epoch 148: val_cvar_emp improved from -10.76401 to -10.76278, saving model to results\\best_tail_by_cvar.weights.h5\n",
      "\n",
      "Epoch 148: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 148: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 10.9699 - tau: -10.2212 - mean_X: -7.7235 - mean_PnL: 0.1365 - mean_Cost: 0.1511 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8510 - var_emp: -9.9904 - mean_abs_X: 7.7235 - val_loss: 10.9372 - val_tau: -10.2210 - val_mean_X: -7.6901 - val_mean_PnL: 0.1272 - val_mean_Cost: 0.1505 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7628 - val_var_emp: -9.8877 - val_mean_abs_X: 7.6901 - lr: 1.5625e-05\n",
      "Epoch 149/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9643 - tau: -10.2209 - mean_X: -7.7236 - mean_PnL: 0.1369 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8458 - var_emp: -10.0154 - mean_abs_X: 7.7236\n",
      "Epoch 149: val_cvar_emp did not improve from -10.76278\n",
      "\n",
      "Epoch 149: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 149: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 8s 410ms/step - loss: 10.9643 - tau: -10.2209 - mean_X: -7.7236 - mean_PnL: 0.1369 - mean_Cost: 0.1516 - turnover_mean: 0.0121 - bound_frac: 0.0000e+00 - cvar_emp: -10.8458 - var_emp: -10.0154 - mean_abs_X: 7.7236 - val_loss: 10.9325 - val_tau: -10.2207 - val_mean_X: -7.6899 - val_mean_PnL: 0.1272 - val_mean_Cost: 0.1504 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.7677 - val_var_emp: -9.9139 - val_mean_abs_X: 7.6899 - lr: 1.5625e-05\n",
      "Epoch 150/150\n",
      "20/20 [==============================] - ETA: 0s - loss: 10.9682 - tau: -10.2206 - mean_X: -7.7234 - mean_PnL: 0.1364 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8460 - var_emp: -9.9863 - mean_abs_X: 7.7234\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 150: val_cvar_emp did not improve from -10.76278\n",
      "\n",
      "Epoch 150: val_tau did not improve from -10.02001\n",
      "\n",
      "Epoch 150: val_mean_abs_X did not improve from 7.66041\n",
      "20/20 [==============================] - 9s 454ms/step - loss: 10.9682 - tau: -10.2206 - mean_X: -7.7234 - mean_PnL: 0.1364 - mean_Cost: 0.1509 - turnover_mean: 0.0120 - bound_frac: 0.0000e+00 - cvar_emp: -10.8460 - var_emp: -9.9863 - mean_abs_X: 7.7234 - val_loss: 10.9441 - val_tau: -10.2205 - val_mean_X: -7.6904 - val_mean_PnL: 0.1269 - val_mean_Cost: 0.1506 - val_turnover_mean: 0.0120 - val_bound_frac: 0.0000e+00 - val_cvar_emp: -10.8026 - val_var_emp: -9.9818 - val_mean_abs_X: 7.6904 - lr: 1.5625e-05\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 10) Training\n",
    "# --------------------------\n",
    "\n",
    "cbs = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", mode=\"min\",\n",
    "        factor=0.5, patience=5, min_lr=1e-5, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\",\n",
    "        patience=12, restore_best_weights=True, min_delta=1e-3, verbose=1\n",
    "    ),\n",
    "    # save weights for the best tail (CVaR)\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(RESULTS_DIR / \"best_tail_by_cvar.weights.h5\"),\n",
    "        monitor=\"val_cvar_emp\", mode=\"max\",\n",
    "        save_best_only=True, save_weights_only=True, verbose=1\n",
    "    ),\n",
    "    # optional: also save weights for best VaR (tau)\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(RESULTS_DIR / \"best_tail_by_var.weights.h5\"),\n",
    "        monitor=\"val_tau\", mode=\"max\",\n",
    "        save_best_only=True, save_weights_only=True, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(RESULTS_DIR / \"best_center_by_absX.weights.h5\"),\n",
    "        monitor=\"val_mean_abs_X\", mode=\"min\",\n",
    "        save_best_only=True, save_weights_only=True, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.TerminateOnNaN(),\n",
    "]\n",
    "\n",
    "history = loss_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd385b4-94be-47e2-9a35-db632be1ade2",
   "metadata": {},
   "source": [
    "## 3.11) Global validation snapshot\n",
    "\n",
    "**What to do here:**\n",
    "- Build a lightweight `eval_model` that outputs **[X, cost, turnover, PnL]** given inputs (reuses the trained backbone + rollout).\n",
    "- Run it on **all** validation paths (large batch; no shuffle).\n",
    "- Compute and print:\n",
    "  - `mean(X)` vs baseline mean of `-Z_T`\n",
    "  - `VaR_α(X)` and `CVaR_α(X)` vs baseline\n",
    "  - `mean(cost)` and **average total turnover per path** (sum over time, average over paths)\n",
    "- Optionally store arrays for Notebook 4 plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb6e791-93dc-4c5b-be45-8aba14fbaa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 126ms/step\n",
      "MAE: model 7.695 vs baseline 7.653\n",
      "=== Global Validation Evaluation ===\n",
      "Mean(XG): -7.69  vs baseline -7.653246879577637\n",
      "VaR_90 : -9.98  vs baseline -23.68\n",
      "CVaR_90: -10.83  vs baseline -31.62\n",
      "Mean Cost: 0.1505\n",
      "Avg Turnover: 3.0240\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 11) Global Validation\n",
    "# --------------------------\n",
    "\n",
    "# Collect full validation set (inputs + targets)\n",
    "xb_full = {\"features\": [], \"dS\": [], \"Z_T\": []}\n",
    "yb_full = []\n",
    "\n",
    "for xb, yb in val_ds:   # iterate batches\n",
    "    for k in xb_full: \n",
    "        xb_full[k].append(xb[k].numpy())\n",
    "    yb_full.append(yb.numpy())\n",
    "\n",
    "# Concatenate into single arrays\n",
    "for k in xb_full:\n",
    "    xb_full[k] = np.concatenate(xb_full[k], axis=0)\n",
    "yb_full = np.concatenate(yb_full, axis=0)\n",
    "\n",
    "\n",
    "eval_model = keras.Model(\n",
    "    inputs=[features_in, dS_in, Z_T_in],\n",
    "    outputs=[X, cost, turnover, PnL]\n",
    ")\n",
    "\n",
    "X_val, cost_val, turnover_val, PnL_val = eval_model.predict(\n",
    "    [xb_full[\"features\"], xb_full[\"dS\"], xb_full[\"Z_T\"]],\n",
    "    batch_size=1024, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "N = X_val.shape[0]\n",
    "\n",
    "# Mean\n",
    "mean_XG = np.mean(X_val)\n",
    "\n",
    "# VaR at 90% (10th percentile)\n",
    "k = int(np.ceil((1 - ALPHA) * N))\n",
    "X_sorted = np.sort(X_val)\n",
    "VaR_90 = X_sorted[k-1]\n",
    "\n",
    "# CVaR at 90% (average of worst 10%)\n",
    "CVaR_90 = np.mean(X_sorted[:k])\n",
    "\n",
    "# Mean cost\n",
    "mean_cost = np.mean(cost_val)\n",
    "\n",
    "# Total turnover per path (sum across timesteps, then average over paths)\n",
    "turnover_total = np.mean(np.sum(turnover_val, axis=1))\n",
    "\n",
    "X_zero = -xb_full[\"Z_T\"]  # wealth is just -Z_T\n",
    "\n",
    "# Zero-hedge baseline\n",
    "X0_sorted = np.sort(X_zero)\n",
    "mean_baseline = np.mean(X_zero)\n",
    "\n",
    "\n",
    "var_baseline = X0_sorted[k-1]\n",
    "\n",
    "hedged_mae = np.mean(np.abs(X_val))             # from eval_model outputs\n",
    "baseline_mae = np.mean(np.abs(-xb_full[\"Z_T\"])) # zero-hedge\n",
    "print(f\"MAE: model {hedged_mae:.3f} vs baseline {baseline_mae:.3f}\")\n",
    "\n",
    "print(\"=== Global Validation Evaluation ===\")\n",
    "print(f\"Mean(XG): {mean_XG:.2f}  vs baseline {mean_baseline}\")\n",
    "print(f\"VaR_90 : {VaR_90:.2f}  vs baseline {var_baseline:.2f}\")\n",
    "print(f\"CVaR_90: {CVaR_90:.2f}  vs baseline {val_cvar_baseline:.2f}\")\n",
    "print(f\"Mean Cost: {mean_cost:.4f}\")\n",
    "print(f\"Avg Turnover: {turnover_total:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f48cd4-4ae6-4bcb-a636-13c6a0b55f61",
   "metadata": {},
   "source": [
    "## 3.12) Test set evaluation & saving artifacts\n",
    "\n",
    "**What to do here:**\n",
    "- Repeat §11 on `test_ds` and report the same metrics.\n",
    "- **Save** to `results/hedging_eval_test_keras.npz`, e.g. keys:\n",
    "  - `X` (terminal wealth), `Z_T`, `PnL`, `cost`, `turnover`, and possibly positions `a` (if you add it as an output)\n",
    "- These feed Notebook 4 for richer diagnostics/plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7354ad19-6eb4-41ee-9dce-35f3268727ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 127ms/step\n",
      "=== Global Test Evaluation ===\n",
      "Mean(X): -7.72  vs baseline -7.65\n",
      "VaR_90 : -10.03  vs baseline -23.68\n",
      "CVaR_90: -10.90  vs baseline -31.62\n",
      "Mean Cost: 0.1512\n",
      "Avg Turnover: 3.0351\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 12) Testing\n",
    "# --------------------------\n",
    "\n",
    "xb_full = {\"features\": [], \"dS\": [], \"Z_T\": []}\n",
    "yb_full = []\n",
    "\n",
    "for xb, yb in test_ds:   # iterate batches\n",
    "    for k in xb_full: \n",
    "        xb_full[k].append(xb[k].numpy())\n",
    "    yb_full.append(yb.numpy())\n",
    "\n",
    "for k in xb_full:\n",
    "    xb_full[k] = np.concatenate(xb_full[k], axis=0)\n",
    "yb_full = np.concatenate(yb_full, axis=0)\n",
    "\n",
    "X_test, cost_test, turnover_test, PnL_test = eval_model.predict(\n",
    "    [xb_full[\"features\"], xb_full[\"dS\"], xb_full[\"Z_T\"]],\n",
    "    batch_size=1024,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "N = X_test.shape[0]\n",
    "\n",
    "mean_XG = np.mean(X_test)\n",
    "\n",
    "k = int(np.ceil((1 - ALPHA) * N))\n",
    "X_sorted = np.sort(X_test)\n",
    "VaR_90 = X_sorted[k-1]\n",
    "CVaR_90 = np.mean(X_sorted[:k])\n",
    "\n",
    "mean_cost = np.mean(cost_test)\n",
    "turnover_total = np.mean(np.sum(turnover_test, axis=1))\n",
    "\n",
    "print(\"=== Global Test Evaluation ===\")\n",
    "print(f\"Mean(X): {mean_XG:.2f}  vs baseline {mean_baseline:.2f}\")\n",
    "print(f\"VaR_90 : {VaR_90:.2f}  vs baseline {var_baseline:.2f}\")\n",
    "print(f\"CVaR_90: {CVaR_90:.2f}  vs baseline {val_cvar_baseline:.2f}\")\n",
    "print(f\"Mean Cost: {mean_cost:.4f}\")\n",
    "print(f\"Avg Turnover: {turnover_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90217f1a-7167-4833-8dbd-e55373f3381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results\\hedging_eval_test_keras_4.npz  (V_T (5000,), Z_T (5000,))\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 13) SAVE\n",
    "# --------------------------\n",
    "# Save V_T (hedged terminal portfolio) and Z_T (payoff) to NPZ\n",
    "#   X_test, cost_test, turnover_test, PnL_test = eval_model.predict(...)\n",
    "#   xb_full[\"Z_T\"] from building the test set\n",
    "\n",
    "V_T_test = (PnL_test.reshape(-1) - cost_test.reshape(-1)).astype(np.float32)  # (N,)\n",
    "Z_T_test = xb_full[\"Z_T\"].reshape(-1).astype(np.float32)                      # (N,)\n",
    "\n",
    "# Sanity check\n",
    "assert V_T_test.shape == Z_T_test.shape, f\"Shape mismatch: {V_T_test.shape} vs {Z_T_test.shape}\"\n",
    "\n",
    "out_path = RESULTS_DIR / \"hedging_eval_test_keras_4.npz\"\n",
    "np.savez_compressed(out_path, V_T=V_T_test, Z_T=Z_T_test)\n",
    "print(f\"Saved: {out_path}  (V_T {V_T_test.shape}, Z_T {Z_T_test.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed381c62-c431-4be9-85d3-12c93abf0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_model.load_weights(RESULTS_DIR / \"best_tail_by_cvar.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd04a9-1747-4bc4-919f-17ae72adb8b5",
   "metadata": {},
   "source": [
    "## 3.13) Interpreting results\n",
    "\n",
    "**What good looks like (directionally):**\n",
    "- `CVaR_α(X)` **much higher** (less negative) than baseline \\( \\text{CVaR}_\\alpha(-Z_T) \\)  \n",
    "  (remember: more negative = worse loss; moving toward zero is improvement)\n",
    "- `VaR_α(X)` improved similarly\n",
    "- `mean(X)` may stay negative (you’re minimizing tail, not MSE); small positive is a bonus\n",
    "- `mean_cost` and `turnover` within realistic bounds (gives credibility)\n",
    "- `bound_frac` small (not exploiting the clamp edge)\n",
    "\n",
    "**If it looks too good to be true:**\n",
    "- Check no look-ahead in features (§2)\n",
    "- Ensure `dS` aligns with time \\(t\\) features\n",
    "- Confirm `Z_T` shape is 1D and used only in `X = -Z_T + ...`\n",
    "\n",
    "---\n",
    "\n",
    "## 3.14) Hyperparameter guide (what changes what)\n",
    "\n",
    "- **`ALPHA` (tail level):**  \n",
    "  Higher (e.g., 0.95) ⇒ focuses on *extreme* worst tail, typically stronger tail protection, possibly larger mean error.  \n",
    "  Lower (e.g., 0.80) ⇒ softer tail, may improve average metrics but weaker extreme-loss control.\n",
    "- **`GAMMA` (cost):**  \n",
    "  Higher ⇒ discourages turnover, reduces cost & noise, might leave some risk unhedged.  \n",
    "  Lower ⇒ more active hedging, better fit, but higher costs / overfitting risk.\n",
    "- **`H_MAX` (clamp):**  \n",
    "  Lower ⇒ policies stay small; safer but under-powered.  \n",
    "  Higher ⇒ more capacity; watch `bound_frac`.\n",
    "- **Backbone size (GRU widths):**  \n",
    "  Larger ⇒ more expressive; use dropout or stronger cost if you see overfitting.\n",
    "- **`LR`, `BATCH`:**  \n",
    "  Tail objectives benefit from moderately large batches (more stable tail estimate). Too small batches produce noisy VaR/CVaR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clustering-env)",
   "language": "python",
   "name": "clustering-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
